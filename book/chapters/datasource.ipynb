{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a19b1c84c1e62af1",
   "metadata": {},
   "source": [
    "# Training and Testing Dataset Overview\n",
    "\n",
    "# Introduction\n",
    "In the realm of environmental research and forecasting, access to reliable and comprehensive datasets is paramount. Four such indispensable sources are gridMET, AMSR, MODIS, and SNOTEL. Each dataset offers unique insights into various aspects of Earth's climate and terrain, contributing significantly to our understanding of environmental dynamics. These datasets serve as the cornerstone for numerous applications, including weather forecasting, ecological modeling, and climate change research. In our **snowcast_wormhole** workflow, we leverage the richness of these datasets to enhance the accuracy and robustness. Let's embark on a detailed exploration of these invaluable data sources.\n",
    "\n",
    "\n",
    "# gridMET Dataset\n",
    "\n",
    "## Introduction\n",
    "gridMET is like having a weather wizard at your fingertips! It's a dataset packed with daily high-spatial resolution (~4-km, 1/24th degree) surface meteorological data covering the contiguous US, spanning from 1979 up to yesterday. It even extends its reach to cover southern British Columbia in real-time products. This dataset provides vital insights into weather patterns, aiding various industries and scientific endeavors.\n",
    "\n",
    "## Insights\n",
    "\n",
    "* It offers a fascinating glimpse into historical weather patterns, allowing users to delve as far back as 1979.\n",
    "* The dataset provides an extensive array of information, including maximum and minimum temperatures, precipitation, radiation, wind velocity, and various other meteorological variables.xx\n",
    "* Scientists and modelers find it invaluable for a myriad of purposes, such as ecological research, agricultural strategizing, hydrological modeling, and beyond.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"../img/gridMET/tmmn-map.png\" alt=\"air_temperature_tmmn Map\" height=\"250\" width=\"250\"/>\n",
    "\n",
    "<img src=\"../img/gridMET/tmmx_map.png\" alt=\"air_temperature_tmmx Map\" height=\"250\" width=\"250\"/>\n",
    "\n",
    "<img src=\"../img/gridMET/evapotranspiration_map.png\" alt=\"potential_evapotranspiration Map\" height=\"250\" width=\"250\"/>\n",
    "\n",
    "<img src=\"../img/gridMET/mean_vapor_pressure_deficit_map.png\" alt=\"mean_vapor_pressure_deficit\"  height=\"250\" width=\"250\"/>\n",
    "\n",
    "<img src=\"../img/gridMET/relative_humidity_rmax_map.png\" alt=\"relative_humidity_rmax map\" height=\"250\" width=\"250\"/>\n",
    "\n",
    "<img src=\"../img/gridMET/relative_humidity_rmin_map.png\" alt=\"relative_humidity_rmin Map\" height=\"250\" width=\"250\"/>\n",
    "\n",
    "<img src=\"../img/gridMET/precipitation_amount.png\" alt=\"precipitation_amount Map\" height=\"250\" width=\"250\"/>\n",
    "\n",
    "<img src=\"../img/gridMET/wind_speed_map.png\" alt=\"wind_speed Map\" height=\"250\" width=\"250\"/>\n",
    "\n",
    "## Characteristics\n",
    "\n",
    "- **Spatial Resolution**: GridMET provides data at a high spatial resolution, typically around 4 kilometers.\n",
    "  \n",
    "- **Temporal Resolution**: The dataset offers data at a daily time step, allowing access to meteorological data for each day.\n",
    "  \n",
    "- **Variables**: GridMET includes meteorological variables such as temperature, precipitation, humidity, wind speed, and solar radiation.\n",
    "  \n",
    "- **Coverage**: The dataset covers the contiguous United States, providing comprehensive meteorological data for this region.\n",
    "  \n",
    "- **Quality**: Data is derived from multiple sources including weather station observations, satellite data, and meteorological models, and is quality-controlled.\n",
    "  \n",
    "- **Long-term Availability**: GridMET provides data spanning several decades, enabling analysis of historical meteorological trends and patterns.\n",
    "\n",
    "## Data Format:\n",
    "\n",
    "GRIDMET data is typically available in common file formats such as NetCDF (Network Common Data Form) or ASCII (plain text) format. NetCDF is widely used for multidimensional scientific data and provides efficient storage and access to large datasets. ASCII format offers simplicity and compatibility with various software tools for data analysis and visualization.\n",
    "\n",
    "## Data Sources and Acquisition:\n",
    "\n",
    "#### Satellite Data:\n",
    "GRIDMET utilizes satellite data from different sources such as the Geostationary Operational Environmental Satellite (GOES) and the Moderate Resolution Imaging Spectroradiometer (MODIS). These satellite observations provide valuable information on temperature, precipitation, humidity, and other atmospheric variables.\n",
    "\n",
    "#### Ground-Based Observations:\n",
    "The dataset incorporates ground-based weather station observations from various networks such as the National Weather Service's Cooperative Observer Program (COOP), the Automated Surface Observing System (ASOS), and the Automated Weather Data Network (AWDN). These observations help in validating and enhancing the accuracy of the dataset.\n",
    "\n",
    "#### Meteorological Models:\n",
    "gridMET also integrates data from numerical weather prediction models like the North American Mesoscale Forecast System (NAM) and the Weather Research and Forecasting (WRF) model. These models provide forecasts and simulations of meteorological variables which are then blended with observed data to create a more complete dataset.\n",
    "\n",
    "## Applications:\n",
    "\n",
    "- Climate research and modeling\n",
    "- Agriculture and crop management\n",
    "- Hydrology and water resource management\n",
    "- Renewable energy assessment\n",
    "- Disaster management and risk assessment\n",
    "- Ecological and environmental studies\n",
    "\n",
    "# gridMET Data Download:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "383cbbb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading http://www.northwestknowledge.net/metdata/data/tmmn_2020.nc\n",
      "downloading http://www.northwestknowledge.net/metdata/data/tmmn_2021.nc\n",
      "downloading http://www.northwestknowledge.net/metdata/data/tmmx_2020.nc\n",
      "downloading http://www.northwestknowledge.net/metdata/data/tmmx_2021.nc\n",
      "downloading http://www.northwestknowledge.net/metdata/data/pr_2020.nc\n",
      "downloading http://www.northwestknowledge.net/metdata/data/pr_2021.nc\n",
      "downloading http://www.northwestknowledge.net/metdata/data/vpd_2020.nc\n",
      "downloading http://www.northwestknowledge.net/metdata/data/vpd_2021.nc\n",
      "downloading http://www.northwestknowledge.net/metdata/data/etr_2020.nc\n",
      "downloading http://www.northwestknowledge.net/metdata/data/etr_2021.nc\n",
      "downloading http://www.northwestknowledge.net/metdata/data/rmax_2020.nc\n",
      "downloading http://www.northwestknowledge.net/metdata/data/rmax_2021.nc\n",
      "downloading http://www.northwestknowledge.net/metdata/data/rmin_2020.nc\n",
      "downloading http://www.northwestknowledge.net/metdata/data/rmin_2021.nc\n",
      "downloading http://www.northwestknowledge.net/metdata/data/vs_2020.nc\n",
      "downloading http://www.northwestknowledge.net/metdata/data/vs_2021.nc\n",
      "reading values from /Users/meghana/gridmet_test_run/gridmet_climatology/rmin_2021.nc\n",
      "['relative_humidity']\n",
      "The file '/Users/meghana/gridmet_test_run/gridmet_climatology/rmin_2021.csv' exists.\n",
      "reading values from /Users/meghana/gridmet_test_run/gridmet_climatology/tmmn_2021.nc\n",
      "['air_temperature']\n",
      "The file '/Users/meghana/gridmet_test_run/gridmet_climatology/tmmn_2021.csv' exists.\n",
      "reading values from /Users/meghana/gridmet_test_run/gridmet_climatology/etr_2021.nc\n",
      "['potential_evapotranspiration']\n",
      "The file '/Users/meghana/gridmet_test_run/gridmet_climatology/etr_2021.csv' exists.\n",
      "reading values from /Users/meghana/gridmet_test_run/gridmet_climatology/etr_2020.nc\n",
      "['potential_evapotranspiration']\n",
      "The file '/Users/meghana/gridmet_test_run/gridmet_climatology/etr_2020.csv' exists.\n",
      "reading values from /Users/meghana/gridmet_test_run/gridmet_climatology/rmin_2020.nc\n",
      "['relative_humidity']\n",
      "The file '/Users/meghana/gridmet_test_run/gridmet_climatology/rmin_2020.csv' exists.\n",
      "reading values from /Users/meghana/gridmet_test_run/gridmet_climatology/tmmn_2020.nc\n",
      "['air_temperature']\n",
      "The file '/Users/meghana/gridmet_test_run/gridmet_climatology/tmmn_2020.csv' exists.\n",
      "reading values from /Users/meghana/gridmet_test_run/gridmet_climatology/tmmx_2021.nc\n",
      "['air_temperature']\n",
      "The file '/Users/meghana/gridmet_test_run/gridmet_climatology/tmmx_2021.csv' exists.\n",
      "reading values from /Users/meghana/gridmet_test_run/gridmet_climatology/tmmx_2020.nc\n",
      "['air_temperature']\n",
      "The file '/Users/meghana/gridmet_test_run/gridmet_climatology/tmmx_2020.csv' exists.\n",
      "reading values from /Users/meghana/gridmet_test_run/gridmet_climatology/vpd_2020.nc\n",
      "['mean_vapor_pressure_deficit']\n",
      "The file '/Users/meghana/gridmet_test_run/gridmet_climatology/vpd_2020.csv' exists.\n",
      "reading values from /Users/meghana/gridmet_test_run/gridmet_climatology/pr_2021.nc\n",
      "['precipitation_amount']\n",
      "The file '/Users/meghana/gridmet_test_run/gridmet_climatology/pr_2021.csv' exists.\n",
      "reading values from /Users/meghana/gridmet_test_run/gridmet_climatology/pr_2020.nc\n",
      "['precipitation_amount']\n",
      "The file '/Users/meghana/gridmet_test_run/gridmet_climatology/pr_2020.csv' exists.\n",
      "reading values from /Users/meghana/gridmet_test_run/gridmet_climatology/vpd_2021.nc\n",
      "['mean_vapor_pressure_deficit']\n",
      "The file '/Users/meghana/gridmet_test_run/gridmet_climatology/vpd_2021.csv' exists.\n",
      "reading values from /Users/meghana/gridmet_test_run/gridmet_climatology/vs_2021.nc\n",
      "['wind_speed']\n",
      "The file '/Users/meghana/gridmet_test_run/gridmet_climatology/vs_2021.csv' exists.\n",
      "reading values from /Users/meghana/gridmet_test_run/gridmet_climatology/rmax_2020.nc\n",
      "['relative_humidity']\n",
      "The file '/Users/meghana/gridmet_test_run/gridmet_climatology/rmax_2020.csv' exists.\n",
      "reading values from /Users/meghana/gridmet_test_run/gridmet_climatology/vs_2020.nc\n",
      "['wind_speed']\n",
      "The file '/Users/meghana/gridmet_test_run/gridmet_climatology/vs_2020.csv' exists.\n",
      "reading values from /Users/meghana/gridmet_test_run/gridmet_climatology/rmax_2021.nc\n",
      "['relative_humidity']\n",
      "The file '/Users/meghana/gridmet_test_run/gridmet_climatology/rmax_2021.csv' exists.\n",
      "Merged ['tmmn_2020.csv', 'tmmn_2021.csv', 'tmmn_merged.csv'] into tmmn_merged.csv\n",
      "Merged ['vs_merged.csv', 'vs_2020.csv', 'vs_2021.csv'] into vs_merged.csv\n",
      "Merged ['rmax_merged.csv', 'rmax_2020.csv', 'rmax_2021.csv'] into rmax_merged.csv\n",
      "Merged ['etr_merged.csv', 'etr_2020.csv', 'etr_2021.csv'] into etr_merged.csv\n",
      "Merged ['vpd_merged.csv', 'vpd_2020.csv', 'vpd_2021.csv'] into vpd_merged.csv\n",
      "Merged ['tmmx_2021.csv', 'tmmx_2020.csv', 'tmmx_merged.csv'] into tmmx_merged.csv\n",
      "Merged ['pr_2021.csv', 'pr_2020.csv', 'pr_merged.csv'] into pr_merged.csv\n",
      "Merged ['rmin_2021.csv', 'rmin_merged.csv', 'rmin_2020.csv'] into rmin_merged.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import urllib.request\n",
    "from datetime import date, datetime\n",
    "\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from pathlib import Path\n",
    "\n",
    "import warnings\n",
    "\n",
    "#Chaging the timeframe to 1 year, instead of 10, for demonstration\n",
    "\n",
    "train_start_date = \"2020-01-03\"\n",
    "train_end_date = \"2021-12-31\"\n",
    "homedir = os.path.expanduser('~')\n",
    "work_dir = f\"{homedir}/gridmet_test_run\"\n",
    "\n",
    "# Suppress FutureWarnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "start_date = datetime.strptime(train_start_date, \"%Y-%m-%d\")\n",
    "end_date = datetime.strptime(train_end_date, \"%Y-%m-%d\")\n",
    "\n",
    "year_list = [start_date.year + i for i in range(end_date.year - start_date.year + 1)]\n",
    "\n",
    "working_dir = work_dir\n",
    "stations = pd.read_csv(f\"{work_dir}/all_snotel_cdec_stations_active_in_westus.csv\")\n",
    "gridmet_save_location = f'{working_dir}/gridmet_climatology'\n",
    "final_merged_csv = f\"{work_dir}/training_all_active_snotel_station_list_elevation.csv_gridmet.csv\"\n",
    "\n",
    "\n",
    "def get_files_in_directory():\n",
    "    f = list()\n",
    "    for files in glob.glob(gridmet_save_location + \"/*.nc\"):\n",
    "        f.append(files)\n",
    "    return f\n",
    "\n",
    "\n",
    "def download_file(url, save_location):\n",
    "    try:\n",
    "        print(\"download_file\")\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            file_content = response.read()\n",
    "        file_name = os.path.basename(url)\n",
    "        save_path = os.path.join(save_location, file_name)\n",
    "        with open(save_path, 'wb') as file:\n",
    "            file.write(file_content)\n",
    "        print(f\"File downloaded successfully and saved as: {save_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while downloading the file: {str(e)}\")\n",
    "\n",
    "\n",
    "def download_gridmet_climatology():\n",
    "    folder_name = gridmet_save_location\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "\n",
    "    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n",
    "    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n",
    "\n",
    "    for var in variables_list:\n",
    "        for y in year_list:\n",
    "            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n",
    "            print(\"downloading\", download_link)\n",
    "            if not os.path.exists(os.path.join(folder_name, var + '_' + '%s' % y + '.nc')):\n",
    "                download_file(download_link, folder_name)\n",
    "\n",
    "\n",
    "def get_gridmet_variable(file_name):\n",
    "    print(f\"reading values from {file_name}\")\n",
    "    result_data = []\n",
    "    ds = xr.open_dataset(file_name)\n",
    "    var_to_extract = list(ds.keys())\n",
    "    print(var_to_extract)\n",
    "    var_name = var_to_extract[0]\n",
    "    \n",
    "    df = pd.DataFrame(columns=['day', 'lat', 'lon', var_name])\n",
    "    \n",
    "    csv_file = f'{gridmet_save_location}/{Path(file_name).stem}.csv'\n",
    "    if os.path.exists(csv_file):\n",
    "    \tprint(f\"The file '{csv_file}' exists.\")\n",
    "    \treturn\n",
    "\n",
    "    for idx, row in stations.iterrows():\n",
    "        lat = row['latitude']\n",
    "        lon = row['longitude']\n",
    "\t\t\n",
    "        subset_data = ds.sel(lat=lat, lon=lon, method='nearest')\n",
    "        subset_data['lat'] = lat\n",
    "        subset_data['lon'] = lon\n",
    "        converted_df = subset_data.to_dataframe()\n",
    "        converted_df = converted_df.reset_index(drop=False)\n",
    "        converted_df = converted_df.drop('crs', axis=1)\n",
    "        df = pd.concat([df, converted_df], ignore_index=True)\n",
    "        \n",
    "    result_df = df\n",
    "    print(\"got result_df : \", result_df.head())\n",
    "    result_df.to_csv(csv_file, index=False)\n",
    "    print(f'completed extracting data for {file_name}')\n",
    "\n",
    "\n",
    "def merge_similar_variables_from_different_years():\n",
    "    files = os.listdir(gridmet_save_location)\n",
    "    file_groups = {}\n",
    "\n",
    "    for filename in files:\n",
    "        base_name, year_ext = os.path.splitext(filename)\n",
    "        parts = base_name.split('_')\n",
    "        if len(parts) == 2 and year_ext == '.csv':\n",
    "            file_groups.setdefault(parts[0], []).append(filename)\n",
    "\n",
    "    for base_name, file_list in file_groups.items():\n",
    "        if len(file_list) > 1:\n",
    "            dfs = []\n",
    "            for filename in file_list:\n",
    "                df = pd.read_csv(os.path.join(gridmet_save_location, filename))\n",
    "                dfs.append(df)\n",
    "            merged_df = pd.concat(dfs, ignore_index=True)\n",
    "            merged_filename = f\"{base_name}_merged.csv\"\n",
    "            merged_df.to_csv(os.path.join(gridmet_save_location, merged_filename), index=False)\n",
    "            print(f\"Merged {file_list} into {merged_filename}\")\n",
    "\n",
    "\n",
    "def merge_all_variables_together():\n",
    "    merged_df = None\n",
    "    file_paths = []\n",
    "\n",
    "    for filename in os.listdir(gridmet_save_location):\n",
    "        if filename.endswith(\"_merged.csv\"):\n",
    "            file_paths.append(os.path.join(gridmet_save_location, filename))\n",
    "\t\n",
    "    rmin_merged_path = os.path.join(gridmet_save_location, 'rmin_merged.csv')\n",
    "    rmax_merged_path = os.path.join(gridmet_save_location, 'rmax_merged.csv')\n",
    "    tmmn_merged_path = os.path.join(gridmet_save_location, 'tmmn_merged.csv')\n",
    "    tmmx_merged_path = os.path.join(gridmet_save_location, 'tmmx_merged.csv')\n",
    "    \n",
    "    df_rmin = pd.read_csv(rmin_merged_path)\n",
    "    df_rmax = pd.read_csv(rmax_merged_path)\n",
    "    df_tmmn = pd.read_csv(tmmn_merged_path)\n",
    "    df_tmmx = pd.read_csv(tmmx_merged_path)\n",
    "    \n",
    "    df_rmin.rename(columns={'relative_humidity': 'relative_humidity_rmin'}, inplace=True)\n",
    "    df_rmax.rename(columns={'relative_humidity': 'relative_humidity_rmax'}, inplace=True)\n",
    "    df_tmmn.rename(columns={'air_temperature': 'air_temperature_tmmn'}, inplace=True)\n",
    "    df_tmmx.rename(columns={'air_temperature': 'air_temperature_tmmx'}, inplace=True)\n",
    "    \n",
    "    df_rmin.to_csv(os.path.join(gridmet_save_location, 'rmin_merged.csv'))\n",
    "    df_rmax.to_csv(os.path.join(gridmet_save_location, 'rmax_merged.csv'))\n",
    "    df_tmmn.to_csv(os.path.join(gridmet_save_location, 'tmmn_merged.csv'))\n",
    "    df_tmmx.to_csv(os.path.join(gridmet_save_location, 'tmmx_merged.csv'))\n",
    "    \n",
    "    if file_paths:\n",
    "        merged_df = pd.read_csv(file_paths[0])\n",
    "        for file_path in file_paths[1:]:\n",
    "            df = pd.read_csv(file_path)\n",
    "            merged_df = pd.concat([merged_df, df], axis=1)\n",
    "        merged_df = merged_df.loc[:, ~merged_df.columns.duplicated()]\n",
    "        merged_df.to_csv(final_merged_csv, index=False)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    download_gridmet_climatology()\n",
    "    \n",
    "    nc_files = get_files_in_directory()\n",
    "    for nc in nc_files:\n",
    "        get_gridmet_variable(nc)\n",
    "    \n",
    "    merge_similar_variables_from_different_years()\n",
    "    merge_all_variables_together()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fe4521",
   "metadata": {},
   "source": [
    "We acquire and consolidate GridMET climate data. Initially, we download GridMET climate data files for specified variables and years, ensuring comprehensive coverage. Subsequently, we extract data for each station from these files and organize it into CSV format, simplifying data handling. Additionally, we intelligently merge similar variables from different years, streamlining data aggregation. Ultimately, we combine all variables into a unified dataset, facilitating seamless analysis or modeling tasks. This automation enhances efficiency and accuracy in climate data processing, benefiting various research or environmental applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e2e7ee",
   "metadata": {},
   "source": [
    "# AMSR Dataset\n",
    "\n",
    "## Introduction\n",
    "### What is AMSR?\n",
    "AMSR, short for Advanced Microwave Scanning Radiometer is a satellite-based instrument designed to measure microwave emissions from the Earth's surface and atmosphere. The AMSR dataset encompasses satellite-derived microwave observations crucial for a myriad of applications including weather forecasting, climate monitoring, and environmental studies. These datasets provide valuable insights into geophysical parameters such as sea surface temperature, soil moisture, sea ice concentration, precipitation, and wind speed over oceans. By collecting data on these factors, AMSR helps scientists better understand how water moves and behaves across the planet. Its observations provide valuable insights into Earth's climate dynamics and hydrological processes, contributing to our overall understanding of the environment.\n",
    "\n",
    "### Quick Look at the Data Collections\n",
    "AMSR-E, or the Advanced Microwave Scanning Radiometer for the Earth Observing System, is like a high-tech detective tool that travels on NASA's Aqua satellite. It gathers information about water on Earth and other important details about our environment. AMSR-E data collections include AMSR/ADEOS-II and AMSR2, hosted by the National Snow and Ice Data Center Distributed Active Archive Center (NSIDC DAAC). These datasets provide a treasure trove of polar observations, facilitating research in climatology, oceanography, hydrology, and more.\n",
    "\n",
    "## Characteristics\n",
    "- **Spatial Resolution**: AMSR provides data at various spatial resolutions depending on the specific instrument version and product. Typically, it offers moderate to high spatial resolution microwave data.\n",
    "\n",
    "- **Temporal Resolution**: AMSR data is available at various temporal resolutions, ranging from daily to monthly, depending on the specific product and parameters.\n",
    "\n",
    "- **Variables**: AMSR measures various parameters such as soil moisture, sea surface temperature, precipitation, snow water equivalent, and sea ice concentration using microwave radiometry.\n",
    "\n",
    "- **Coverage**: AMSR provides global coverage, allowing for the monitoring of environmental parameters across different regions of the Earth.\n",
    "\n",
    "- **Quality**: Data from AMSR undergoes rigorous quality control processes to ensure accuracy and reliability, considering factors such as calibration and validation against ground-based measurements.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://developers.google.com/earth-engine/datasets/images/TRMM/TRMM_3B43V7_sample.png\" alt=\"Sample Image from TRMM_3B43V7 dataset\" width=\"400\">\n",
    "</p>\n",
    "<p align=\"center\">AMSR from TRMM 3B43V7 dataset</p>\n",
    "\n",
    "\n",
    "## Data Format\n",
    "\n",
    "The Advanced Microwave Scanning Radiometer (AMSR) data is commonly stored in HDF5 format, providing a hierarchical structure for organizing datasets such as brightness temperature, sea surface temperature, and soil moisture. Within the HDF5 file, data parameters are organized into groups, with subgroups representing different configurations or subsets of the data. Metadata and geolocation information are typically stored separately, offering additional details about the data.\n",
    "\n",
    "## AMSR Data Collections\n",
    "### AMSR/ADEOS-II\n",
    "AMS/ADEOS-II, operating on the Advanced Earth Observing Satellite-II (ADEOS-II) platform, was the initial version of the AMSR instrument, providing passive microwave measurements from early 2003 to October 24, 2003. Offering Level-1A and Level-2A products, it served as a crucial tool for studying changes in polar ice caps, global precipitation patterns, and oceanic circulation. This data has been instrumental in enhancing our understanding of Earth's climate dynamics and informing research across various scientific disciplines.\n",
    "\n",
    "### AMSR2\n",
    "AMSR2, launched in 2012 onboard the Global Change Observation Mission-Water (GCOM-W1) satellite, represents the next generation of AMSR instruments. It continues the legacy of AMSR-E, capturing observations with improved spatial resolution and enhanced capabilities. AMSR2 data has been instrumental in monitoring sea ice extent, ocean surface winds, and soil moisture dynamics at global scales.\n",
    "\n",
    "### Hosted by NSIDC DAAC\n",
    "The NSIDC DAAC serves as the primary repository for AMSR-related data, ensuring that these valuable datasets are freely accessible to the scientific community and the public. The center provides data discovery, access, and user support services, facilitating research in cryospheric and hydrological sciences, climate modeling, and environmental monitoring.\n",
    "\n",
    "## Applications\n",
    "1. **Weather Forecasting**: AMSR data aids in short-term weather forecasting by providing insights into atmospheric moisture content and precipitation patterns.\n",
    "\n",
    "2. **Climate Monitoring**: AMSR datasets contribute to long-term climate monitoring efforts by providing data on parameters like sea surface temperature and sea ice concentration.\n",
    "\n",
    "3. **Oceanography**: AMSR data enables the study of ocean surface properties such as sea surface temperature, wind speed, and ocean salinity, facilitating research in oceanography and marine science.\n",
    "\n",
    "4. **Hydrology**: AMSR-derived soil moisture data supports hydrological modeling, drought monitoring, and water resource management by providing information on soil moisture content and surface water availability.\n",
    "\n",
    "5. **Cryosphere Studies**: AMSR datasets are crucial for studying the cryosphere, including monitoring changes in snow cover extent, snow water equivalent, and sea ice concentration, contributing to our understanding of climate change impacts in polar regions.\n",
    "\n",
    "# AMSR Dataset Download\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "244bcd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "def generate_links(start_year, end_year):\n",
    "    '''\n",
    "    Generate a list of download links for AMSR daily snow data files.\n",
    "\n",
    "    Args:\n",
    "        start_year (int): The starting year.\n",
    "        end_year (int): The ending year (inclusive).\n",
    "\n",
    "    Returns:\n",
    "        list: A list of download links for AMSR daily snow data files.\n",
    "    '''\n",
    "    base_url = \"https://n5eil01u.ecs.nsidc.org/AMSA/AU_DySno.001/\"\n",
    "    date_format = \"%Y.%m.%d\"\n",
    "    delta = timedelta(days=1)\n",
    "\n",
    "    start_date = datetime(start_year, 1, 1)\n",
    "    end_date = datetime(end_year + 1, 1, 1)\n",
    "\n",
    "    links = []\n",
    "    current_date = start_date\n",
    "\n",
    "    while current_date < end_date:\n",
    "        date_str = current_date.strftime(date_format)\n",
    "        link = base_url + date_str + \"/AMSR_U2_L3_DailySnow_B02_\" + date_str + \".he5\"\n",
    "        links.append(link)\n",
    "        current_date += delta\n",
    "\n",
    "    return links\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_year = 2019\n",
    "    end_year = 2022\n",
    "\n",
    "    links = generate_links(start_year, end_year)\n",
    "    homedir = os.path.expanduser('~')\n",
    "    working_dir = f\"{homedir}/gridmet_test_run\"\n",
    "    with open(f\"{working_dir}/amsr/download_links.txt\", \"w\") as txt_file:\n",
    "      for l in links:\n",
    "        txt_file.write(\" \".join(l) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f1f6ac",
   "metadata": {},
   "source": [
    "# MODIS Dataset\n",
    "\n",
    "## Introduction\n",
    "### What is MODIS?\n",
    "MODIS, which stands for MODerate Resolution Imaging Spectroradiometer, is an advanced instrument operating aboard both the Terra and Aqua spacecraft. It captures a comprehensive view of Earth's surface, oceans, and atmosphere. The MODIS dataset is a comprehensive collection of Earth observation data captured by the MODIS instruments. Scientists use MODIS data to track changes in things like land cover, weather patterns, ice and snow, and the color of the oceans. MODIS boasts a remarkable viewing swath width of 2,330 km and covers the entire Earth surface every one to two days. With 36 spectral bands ranging from 0.405 to 14.385 µm, it provides detailed data at three spatial resolutions: 250m, 500m, and 1,000m.\n",
    "\n",
    "## Characteristics\n",
    "- **Spatial Resolution**: MODIS provides data at moderate spatial resolutions ranging from 250 meters to 1 kilometer, depending on the specific product and spectral band.\n",
    "\n",
    "- **Temporal Resolution**: MODIS offers daily global coverage, providing data at a high temporal resolution suitable for monitoring dynamic environmental processes.\n",
    "\n",
    "- **Variables**: MODIS measures various Earth surface parameters including land cover, land surface temperature, vegetation indices, fire occurrence, ocean color, and atmospheric properties.\n",
    "\n",
    "- **Coverage**: MODIS provides global coverage, capturing data over land, ocean, and atmosphere, facilitating multi-disciplinary Earth observation studies.\n",
    "\n",
    "- **Quality**: MODIS data undergoes extensive calibration and validation processes to ensure accuracy and reliability, with quality flags provided to identify potential data anomalies.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://developers.google.com/earth-engine/datasets/images/YALE/YALE_YCEO_UHI_Summer_UHI_yearly_pixel_v4_sample.png\" alt=\"Sample Image from YALE_YCEO_UHI dataset\" width=\"400\">\n",
    "</p>\n",
    "<p align=\"center\">MODIS from YALE YCEO UHI dataset</p>\n",
    "\n",
    "\n",
    "## Data Format\n",
    "MODIS data are typically available in Hierarchical Data Format (HDF) or NetCDF formats, which are widely used for storing and distributing Earth observation data. These formats facilitate efficient data access, manipulation, and analysis using various software tools and programming languages commonly employed in the Earth sciences community.\n",
    "\n",
    "## MODIS Direct Broadcast\n",
    "Users with x-band receiving systems can capture regional data directly from the spacecraft using the MODIS Direct Broadcast signal, enhancing real-time monitoring capabilities.\n",
    "\n",
    "# fSCA\n",
    "\n",
    "Fractional Snow Covered Area (fSCA) is a metric used in the field of snow science and environmental studies to quantify the proportion of a given area that is covered by snow. It is derived from remote sensing data, particularly from sensors like Landsat, which capture images of the Earth's surface in various spectral bands. By analyzing these images, researchers can differentiate between snow-covered and snow-free areas, allowing them to calculate the percentage of the landscape covered by snow at a particular point in time. fSCA is valuable for understanding snow distribution patterns, monitoring changes in snow cover over time, and aiding in snowmelt and water resource management. It plays a crucial role in snowpack modeling, avalanche forecasting, and climate change research, providing essential data for informing decision-making processes related to snow-dependent ecosystems and human activities.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ddb8f3",
   "metadata": {},
   "source": [
    "# SNOTEL dataset\n",
    "\n",
    "## Introduction\n",
    "### What is SNOTEL?\n",
    "The SNOwpackTELemetryNetwork (SNOTEL) is an automated system of snowpack and climate sensors managed by the Natural Resources Conservation Service (NRCS) in the Western United States, offering critical data for water supply forecasting, flood prediction, and climate research. SNOTEL provides real-time data on snow water equivalent, snow depth, precipitation, and temperature from remote mountainous regions, aiding in understanding hydroclimatic conditions. SNOTEL offers comprehensive snowpack and climate data from over 900 sites, helping monitor snowpack, precipitation, temperature, and other climatic conditions in the western U.S.The SNOTEL dataset serves as a valuable resource for a wide range of stakeholders, contributing to informed decision-making in various sectors impacted by snowpack and climate conditions.\n",
    "\n",
    "## SNOTEL Network Overview\n",
    "### Composition of SNOTEL\n",
    "- Comprising over 900 automated sites in remote, high-elevation mountain watersheds.\n",
    "- Monitors snowpack, precipitation, temperature, and other climatic parameters.\n",
    "\n",
    "### Operations and Data Collection\n",
    "- Sites operate unattended and without maintenance for extended periods.\n",
    "- Standard sensor configuration includes snow pillow, precipitation gauge, and temperature sensors.\n",
    "\n",
    "## Telemetry and Data Transmission\n",
    "### Data Collection and Storage\n",
    "- Dataloggers installed in equipment shelters collect and store data.\n",
    "- Various telemetry systems transmit data back to the Water and Climate Information System.\n",
    "\n",
    "### Enhanced Site Capabilities\n",
    "- Enhanced sites equipped with soil moisture, soil temperature, solar radiation, wind speed, and relative humidity sensors.\n",
    "- Tailored configurations based on physical conditions and climate requirements.\n",
    "\n",
    "## Characteristics\n",
    "**Spatial Resolution**: SNOTEL provides data at a network of monitoring sites distributed across mountainous regions, typically covering areas with varying spatial resolutions depending on the density of monitoring stations.\n",
    "\n",
    "**Temporal Resolution**: SNOTEL data is typically collected at hourly intervals, providing high temporal resolution data for monitoring snowpack conditions and related hydrological variables.\n",
    "\n",
    "**Variables**: SNOTEL measures snow water equivalent, snow depth, temperature, precipitation, and soil moisture at monitoring sites in mountainous regions.\n",
    "\n",
    "**Coverage**: SNOTEL stations are primarily located in the western United States, covering areas with significant snowpack and water resource management importance.\n",
    "\n",
    "**Quality**: SNOTEL data undergoes quality control procedures to ensure accuracy and reliability, including calibration checks and validation against manual measurements.\n",
    "\n",
    "## Data Format\n",
    "The Snow Telemetry (SNOTEL) data format encompasses structured datasets collected from remote automated stations situated in mountainous regions, monitoring snowpack, weather, and hydrological parameters. Key aspects include recorded parameters such as snow water equivalent (SWE), snow depth, air temperature, and precipitation, timestamped to denote observation times and often stored at varying resolutions like hourly or daily intervals. Quality control flags accompany data points to denote reliability, while metadata provides station details and sensor calibration information. SNOTEL data is commonly stored in formats like CSV, TSV, HDF5, or netCDF, accessible through agency websites, data portals, or APIs. This format facilitates applications spanning water resource management, climate research, agriculture, recreation, hydrological modeling, and ecological studies.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://www.climate.gov/sites/default/files/2021-08/DatasetGallery_Snow-Water-Equivalent-in-Western-Basins-Interactive-Graph_thumb_16x9.png\" alt=\"Snow Water Equivalent in Western Basins\" width=\"600\">\n",
    "</p>\n",
    "<p align=\"center\">Snow Water Equivalent in Western Basins</p>\n",
    "<br>\n",
    "\n",
    "<img src=\"../img/SNOTEL.jpeg\" alt=\"Snow Water Equivalent Percent NRCS 1991-2020 Median April 6 2024\" width=\"600\" align=\"center\">\n",
    "\n",
    "<p align=\"center\">Snow Water Equivalent Percent NRCS 1991-2020 Median April 6 2024</p>\n",
    "\n",
    "\n",
    "## Applications\n",
    "\n",
    "**Water Resource Management**:\n",
    "   - *Snowpack Monitoring*: Assessing snowpack depth and SWE helps in forecasting water availability for irrigation, hydropower generation, and municipal water supply.\n",
    "   - *Runoff Forecasting*: Data from SNOTEL stations aids in predicting spring runoff, facilitating reservoir management and flood control.\n",
    "\n",
    "**Climate Research**:\n",
    "   - *Long-term Climate Trends*: Historical data enables researchers to study long-term climate patterns, including changes in snowfall, temperature, and precipitation.\n",
    "   - *Climate Change Studies*: SNOTEL data is utilized to understand the impacts of climate change on snowpack dynamics, water resources, and ecosystems.\n",
    "\n",
    "**Agriculture and Forestry**:\n",
    "   - *Crop Planning*: Farmers use snowpack data to anticipate water availability during the growing season, aiding in crop planning and irrigation scheduling.\n",
    "   - *Forest Management*: Forestry agencies utilize SNOTEL data for assessing wildfire risk, planning timber harvests, and monitoring forest health.\n",
    "\n",
    "**Recreation and Tourism**:\n",
    "   - *Winter Sports Planning*: Ski resorts and recreational outfitters rely on snowpack data for planning activities such as skiing, snowboarding, and snowmobiling.\n",
    "   - *Summer Recreation*: Understanding snowmelt timing and water availability helps in planning summer recreational activities like hiking, fishing, and camping.\n",
    "\n",
    "# SNOTEL Dataset Download Instructions\n",
    "\n",
    "Because snow has a higher albedo than most other land cover types, it can cause the seasonal changes in the albedo of a landscape to be quite dramatic. The Soil Climate Analysis Network (SCAN) and the SNOwpack TELemetry (SNOWTEL) network provide snow depth and snow water equivalent (the amount of water contained in a snowpack) data for many sites across the United States.\n",
    "\n",
    "### Step 1: Navigate to the SCAN/SNOWTEL website\n",
    "- Visit the [SCAN/SNOWTEL Website](http://www.wcc.nrcs.usda.gov/nwcc/inventory).\n",
    "\n",
    "### Step 2: Choose Data Product and Location\n",
    "- Select the data product you are interested in (e.g., Snow Depth or Snow Water Equivalent) from the drop-down menu under *Element*.\n",
    "- Choose a State/County or Basin using the drop-down menus provided.\n",
    "\n",
    "### Step 3: View Inventory\n",
    "- Click on 'View Inventory' to see available stations in your selected area.\n",
    "  - If no results are returned, consider widening your search.\n",
    "\n",
    "### Step 4: Select Station and Data\n",
    "- Click 'View' next to the station of interest to access its page.\n",
    "- Use the table to select the data you need:\n",
    "  - Choose the data product (Snow Depth or Snow Water Equivalent).\n",
    "  - Select ‘Daily’ in the Time Series column.\n",
    "  - Choose the format ('chart' for visualization or 'csv' for download).\n",
    "  - View current data by selecting the desired time frame in the yellow column and clicking 'View Current', or view historic data by selecting the year and time in the green column and clicking 'View Historic'.\n",
    "\n",
    "### Step 5: Download Data\n",
    "- Save the downloaded CSV file to your computer for further analysis.\n",
    "\n",
    "**For map visualization of SNOWTEL stations, click on ‘SNOWTEL data’ under ‘Climate Monitoring’ in the right panel. The maps are clickable for station selection.**\n",
    "\n",
    "For more information, visit the [NRCS SNOTEL page](https://www.nrcs.usda.gov/wps/portal/wcc/home/aboutUs/monitoringPrograms/automatedSnowMonitoring).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e005299a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/meghana/Documents/swe-workflow-book/book/chapters', '/Users/meghana', '/opt/anaconda3/lib/python311.zip', '/opt/anaconda3/lib/python3.11', '/opt/anaconda3/lib/python3.11/lib-dynload', '', '/Users/meghana/.local/lib/python3.11/site-packages', '/opt/anaconda3/lib/python3.11/site-packages', '/opt/anaconda3/lib/python3.11/site-packages/aeosa']\n",
      "https://www.nohrsc.noaa.gov/nearest/index.html?city=40.05352381745094%2C-106.04027196859343&county=&l=5&u=e&y=2022&m=5&d=4\n",
      "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/html4/loose.dtd\" >\n",
      "<html lang=\"en\">\n",
      "<head>\n",
      "\t<meta http-equiv=\"Content-Type\" CONTENT=\"text/html; charset=utf-8\" >\n",
      "\t<link rel=\"stylesheet\" type=\"text/css\" href=\"/css/main.css\" >\n",
      "\t<link href=\"/favicon.ico\" rel=\"shortcut icon\" >\n",
      "\t<meta http-equiv=\"Cache-Control\" content=\"no-cache\" >\n",
      "\t<meta name=\"DC.creator\" content=\"National Operational Hydrologic Remote Sensing Center\" >\n",
      "\t<meta name=\"DC.publisher\" content=\"NOAA's National Weather Service\" >\n",
      "\t<meta name=\"DC.contributor\" content=\"National Operational Hydrologic Remote Sensing Center\" >\n",
      "\t<meta name=\"DC.language\" content=\"EN-US\" >\n",
      "<title>Nearest Observations - NOHRSC - The ultimate source for snow information</title>\n",
      "<meta name=\"DC.title\" content=\"Nearest Observations - NOHRSC - The ultimate source for snow information\">\n",
      "<meta name=\"DC.description\" content=\"A listing of nearby observations to a given point and date\">\n",
      "<meta name=\"DC.date.created\" scheme=\"ISO8601\" content=\"2009-01-12\">\n",
      "<meta name=\"DC.date.reviewed\" scheme=\"ISO8601\" content=\"2022-11-14\">\n",
      "\t<script type=\"text/javascript\">\n",
      "\t</script>\n",
      "\t<!-- Global site tag (gtag.js) - Google Analytics -->\n",
      "\t<script type=\"text/javascript\" async src=\"https://www.googletagmanager.com/gtag/js?id=UA-43953030-10\"></script>\n",
      "\t<script type=\"text/javascript\">\n",
      "\t  window.dataLayer = window.dataLayer || [];\n",
      "\t  function gtag(){dataLayer.push(arguments);}\n",
      "\t  gtag('js', new Date());\n",
      "\t  gtag('config', 'UA-43953030-10');\n",
      "\t</script>\n",
      "</head>\n",
      "<body>\n",
      "\t<table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"background-image : url(/images/topbanner.jpg)\">\n",
      "\t\t<tr>\n",
      "\t\t\t<td align=\"right\" height=\"19\">\n",
      "\t\t\t\t<a href=\"#content\"><img src=\"/images/skipgraphic.gif\" alt=\"(content link)\" height=\"1\" width=\"1\" border=\"0\"></a>\n",
      "\t\t\t\t<a href=\"https://www.nws.noaa.gov\"><span class=\"nwslink\">weather.gov</span></a>\n",
      "\t\t\t\t&nbsp;&nbsp;&nbsp;\n",
      "\t\t\t</td>\n",
      "\t\t</tr>\n",
      "\t</table>\n",
      "\t<table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\">\n",
      "\t\t<tr>\n",
      "\t\t\t<td rowspan=\"2\" width=\"85\"><a href=\"https://www.noaa.gov\"><img src=\"/images/titleleft_noaa.jpg\" alt=\"NOAA link\" width=\"85\" height=\"78\" border=\"0\"></a></td>\n",
      "\t\t\t<td align=\"left\" width=\"500\" height=\"20\" style=\"background : url(/images/blank_title.jpg);\"><div class=\"source\">National Weather Service</div></td>\n",
      "\t\t\t<td rowspan=\"2\" style=\"background-image : url(/images/title_bg.jpg)\">&nbsp;</td>\n",
      "\t\t\t<td rowspan=\"2\" width=\"85\" align=\"right\"><a href=\"https://www.nws.noaa.gov\"><img src=\"/images/titleright_nws.jpg\" alt=\"NWS link\" width=\"85\" height=\"78\" border=\"0\"></a></td>\n",
      "\t\t</tr>\n",
      "\t\t<tr>\n",
      "\t\t\t<td width=\"500\" height=\"58\" style=\"background : url(/images/blank_name.jpg);\" class=\"location\"><a href=\"/\">National Operational Hydrologic<br> Remote Sensing Center</a></td>\n",
      "\t\t</tr>\n",
      "\t</table>\n",
      "\t<table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" style=\"background-image : url(/images/navbar_bg.gif)\" width=\"100%\" class=\"nav\">\n",
      "\t\t<tr>\n",
      "\t\t\t<td align=\"left\" valign=\"top\" width=\"94\"><img src=\"/images/navbar_left.jpg\" alt=\"\" width=\"94\" height=\"23\" border=\"0\"></td>\n",
      "\t\t\t<td class=\"nav\" width=\"15%\" align=\"center\" nowrap><a href=\"/\">Home</a></td>\n",
      "\t\t\t<td class=\"nav\" width=\"15%\" align=\"center\"><a href=\"https://www.weather.gov/news\" title=\"National Weather Service News\">News</a></td>\n",
      "\t\t\t<td class=\"nav\" width=\"20%\" align=\"center\"><a href=\"https://www.nws.noaa.gov/organization.html\" title=\"National Weather Service Organization\">Organization</a></td>\n",
      "\t\t\t<td align=\"left\" class=\"searchinput\" width=\"20%\" nowrap=\"nowrap\">\n",
      "\t\t\t\t<form action=\"https://search.usa.gov/search\" method=\"get\" name=\"query\" id=\"query\"\n",
      "\t\t\t\t style=\"margin-bottom:0; margin-top:0;\">\n",
      "\t\t\t\t<label for=\"search\" class=\"yellow\">Search</label>&nbsp;&nbsp;\n",
      "\t\t\t\t<input type=\"hidden\" name=\"affiliate\" value=\"nws.noaa.gov\" >\n",
      "\t\t\t\t<input type=\"text\" name=\"query\" id=\"search\" value=\"Enter Search Here\"\n",
      "\t\t\t\t size=\"20\" maxlength=\"256\" onfocus=\"this.value='';\" title=\"Search all NWS sites here\">&nbsp;\n",
      "\t\t\t\t<input type=\"submit\" id=\"submit\" value=\"Go\" >\n",
      "\t\t\t\t</form>\n",
      "\t\t\t</td>\n",
      "\t\t\t<td width=\"10%\">&nbsp;</td>\n",
      "\t\t\t<td align=\"right\" valign=\"bottom\" width=\"24\"><img src=\"/images/navbar_right.jpg\" alt=\"\" width=\"24\" height=\"23\" border=\"0\"></td>\n",
      "\t\t</tr>\n",
      "\t</table>\n",
      "\t<table cellspacing=\"0\" cellpadding=\"0\">\n",
      "\t\t<tr valign=\"top\">\n",
      "\t\t\t<td class=\"nav\" width=\"130\">\n",
      "<dl>\n",
      "<dd><a href=\"/\">Home</a></dd>\n",
      "</dl>\n",
      "<dl>\n",
      "<dt>Snow Information</dt>\n",
      "<dd><a href=\"/nsa/\" title=\"An overview of snow around the country\">National Analyses</a></dd>\n",
      "<dd><a href=\"/interactive/html/map.html\" title=\"Explore NOHRSC products and create your own maps\">Interactive Maps</a></dd>\n",
      "<dd><a href=\"/earth/\" title=\"A listing of experimental products for use with KML interpreter software\">3D Visualization</a></dd>\n",
      "<dd><a href=\"/snowsurvey/\" title=\"Current information about our snow surveys\">Airborne Surveys</a></dd>\n",
      "<dd><a href=\"/snowfall/\" title=\"Daily maps of observed snowfall\">Snowfall Analysis</a></dd>\n",
      "<dd><a href=\"/nh_snowcover/\">Satellite Products</a></dd>\n",
      "<dd><a href=\"/forecasts/\">Forecasts</a></dd>\n",
      "<dd><a href=\"/archived_data/\" title=\"Information on where to acquire NOHRSC raster data\">Data Archive</a></dd>\n",
      "<dd><a href=\"/shef_archive/\" title=\"Browse an archive of SHEF text messages\">SHEF Products</a></dd>\n",
      "</dl>\n",
      "<form name=\"nearest\" action=\"/nearest/index.html\">\n",
      "<dl>\n",
      "<dt>Observations near</dt>\n",
      "<dd><input type=\"text\" size=\"9\" name=\"city\" value=\"City, ST\" title=\"Search for snow observations near a city. Press enter or select the go button to submit request\" onfocus=\"this.value='';\">\n",
      "<input type=\"submit\" value=\"Go\"></dd>\n",
      "</dl>\n",
      "</form>\n",
      "<dl>\n",
      "<dt>Science/Technology</dt>\n",
      "<dd><a href=\"/technology/\" title=\"More detailed information about the NOHRSC\">NOHRSC</a></dd>\n",
      "<dd><a href=\"/gisdatasets/\" title=\"Shapefiles available for download\">GIS Data Sets</a></dd>\n",
      "<dd><a href=\"/special/\" title=\"Satellite/GIS images for certain projects\">Special Purpose Imagery</a></dd>\n",
      "</dl>\n",
      "<dl>\n",
      "<dt>About The NOHRSC</dt>\n",
      "<dd><a href=\"/directory/\" title=\"Meet the staff at the NOHRSC\">Staff</a></dd>\n",
      "</dl>\n",
      "<dl>\n",
      "<dt>NOAA Links</dt>\n",
      "<dd><a href=\"https://www.ncdc.noaa.gov/snow-and-ice/\">Snow Climatology</a></dd>\n",
      "<dd><a href=\"/links.html\">Related Links</a></dd>\n",
      "</dl>\n",
      "<dl>\n",
      "<dt>Help</dt>\n",
      "<dd><a href=\"/help/\" title=\"NOHRSC web site help\">Help and FAQ</a></dd>\n",
      "<dd><a href=\"/sitemap.html\">Site Map</a></dd>\n",
      "</dl>\n",
      "<dl>\n",
      "<dt>Contact Us</dt>\n",
      "<dd><a href=\"/contact.html\">Please Send Us Comments!</a></dd>\n",
      "</dl>\n",
      "<center>\n",
      "<a href=\"https://www.usa.gov\"><img src=\"/images/usagov_logo_color_110w.gif\" alt=\"USA.gov is the U.S. Government's official Web portal to all Federal, state and local government Web resources and services.\" width=\"110\" height=\"30\" border=\"0\"></a>\n",
      "<br>\n",
      "</center>\n",
      "\t\t\t</td>\n",
      "\t\t\t<td id=\"content_block\">\n",
      "\t\t\t\t<a href=\"\" name=\"content\"></a>\n",
      "<center><strong>Nearest observations to</strong></center>\n",
      "<center><h2>40.05&deg;N, -106.04&deg;W</h2></center>\n",
      "<strong>Note: these data are unofficial and provisional.</strong><br>\n",
      "<form name=\"data\" action=\"/nearest/index.html\">\n",
      "<fieldset>\n",
      "<legend><b>Location and Date</b></legend>\n",
      "<label title=\"Enter City, ST (or Latitude, Longitude)\">Enter your \"City, ST (or Latitude, Longitude)\" <input type=\"text\" size=\"16\" maxlength=\"80\" name=\"city\" value=\"40.05&deg;N, -106.04&deg;W\"></label>\n",
      "<input type=\"hidden\" name=\"county\" value=\"\">\n",
      "<input type=\"submit\" value=\"Go\" title=\"Click to refresh screen\"><br><br>\n",
      "<input type=\"hidden\" name=\"l\" value=\"5\">\n",
      "<select name=\"u\" title=\"Units\" size=\"1\" class=\"smallform\">\n",
      "<option value=\"e\" class=\"smallform\" selected>English</option>\n",
      "<option value=\"m\" class=\"smallform\">Metric</option>\n",
      "</select>\n",
      " &nbsp;\n",
      "<select name=\"y\" title=\"Year\" size=\"1\" class=\"smallform\">\n",
      "<option value=\"2003\" class=\"smallform\">2003</option>\n",
      "<option value=\"2004\" class=\"smallform\">2004</option>\n",
      "<option value=\"2005\" class=\"smallform\">2005</option>\n",
      "<option value=\"2006\" class=\"smallform\">2006</option>\n",
      "<option value=\"2007\" class=\"smallform\">2007</option>\n",
      "<option value=\"2008\" class=\"smallform\">2008</option>\n",
      "<option value=\"2009\" class=\"smallform\">2009</option>\n",
      "<option value=\"2010\" class=\"smallform\">2010</option>\n",
      "<option value=\"2011\" class=\"smallform\">2011</option>\n",
      "<option value=\"2012\" class=\"smallform\">2012</option>\n",
      "<option value=\"2013\" class=\"smallform\">2013</option>\n",
      "<option value=\"2014\" class=\"smallform\">2014</option>\n",
      "<option value=\"2015\" class=\"smallform\">2015</option>\n",
      "<option value=\"2016\" class=\"smallform\">2016</option>\n",
      "<option value=\"2017\" class=\"smallform\">2017</option>\n",
      "<option value=\"2018\" class=\"smallform\">2018</option>\n",
      "<option value=\"2019\" class=\"smallform\">2019</option>\n",
      "<option value=\"2020\" class=\"smallform\">2020</option>\n",
      "<option value=\"2021\" class=\"smallform\">2021</option>\n",
      "<option value=\"2022\" class=\"smallform\" selected>2022</option>\n",
      "<option value=\"2023\" class=\"smallform\">2023</option>\n",
      "<option value=\"2024\" class=\"smallform\">2024</option>\n",
      "</select>\n",
      " &nbsp;\n",
      "<select name=\"m\" title=\"Month\" size=\"1\" class=\"smallform\">\n",
      "<option value=\"1\" class=\"smallform\">January</option>\n",
      "<option value=\"2\" class=\"smallform\">February</option>\n",
      "<option value=\"3\" class=\"smallform\">March</option>\n",
      "<option value=\"4\" class=\"smallform\">April</option>\n",
      "<option value=\"5\" class=\"smallform\" selected>May</option>\n",
      "<option value=\"6\" class=\"smallform\">June</option>\n",
      "<option value=\"7\" class=\"smallform\">July</option>\n",
      "<option value=\"8\" class=\"smallform\">August</option>\n",
      "<option value=\"9\" class=\"smallform\">September</option>\n",
      "<option value=\"10\" class=\"smallform\">October</option>\n",
      "<option value=\"11\" class=\"smallform\">November</option>\n",
      "<option value=\"12\" class=\"smallform\">December</option>\n",
      "</select>\n",
      " &nbsp;\n",
      "<select name=\"d\" title=\"Day\" size=\"1\" class=\"smallform\">\n",
      "<option value=\"1\" class=\"smallform\">1</option>\n",
      "<option value=\"2\" class=\"smallform\">2</option>\n",
      "<option value=\"3\" class=\"smallform\" selected>3</option>\n",
      "<option value=\"4\" class=\"smallform\">4</option>\n",
      "<option value=\"5\" class=\"smallform\">5</option>\n",
      "<option value=\"6\" class=\"smallform\">6</option>\n",
      "<option value=\"7\" class=\"smallform\">7</option>\n",
      "<option value=\"8\" class=\"smallform\">8</option>\n",
      "<option value=\"9\" class=\"smallform\">9</option>\n",
      "<option value=\"10\" class=\"smallform\">10</option>\n",
      "<option value=\"11\" class=\"smallform\">11</option>\n",
      "<option value=\"12\" class=\"smallform\">12</option>\n",
      "<option value=\"13\" class=\"smallform\">13</option>\n",
      "<option value=\"14\" class=\"smallform\">14</option>\n",
      "<option value=\"15\" class=\"smallform\">15</option>\n",
      "<option value=\"16\" class=\"smallform\">16</option>\n",
      "<option value=\"17\" class=\"smallform\">17</option>\n",
      "<option value=\"18\" class=\"smallform\">18</option>\n",
      "<option value=\"19\" class=\"smallform\">19</option>\n",
      "<option value=\"20\" class=\"smallform\">20</option>\n",
      "<option value=\"21\" class=\"smallform\">21</option>\n",
      "<option value=\"22\" class=\"smallform\">22</option>\n",
      "<option value=\"23\" class=\"smallform\">23</option>\n",
      "<option value=\"24\" class=\"smallform\">24</option>\n",
      "<option value=\"25\" class=\"smallform\">25</option>\n",
      "<option value=\"26\" class=\"smallform\">26</option>\n",
      "<option value=\"27\" class=\"smallform\">27</option>\n",
      "<option value=\"28\" class=\"smallform\">28</option>\n",
      "<option value=\"29\" class=\"smallform\">29</option>\n",
      "<option value=\"30\" class=\"smallform\">30</option>\n",
      "<option value=\"31\" class=\"smallform\">31</option>\n",
      "</select>\n",
      " &nbsp;\n",
      "<input type=\"submit\" name=\"i\" value=\" - \" title=\"Back one day\"> &nbsp;\n",
      "<input type=\"submit\" name=\"i\" value=\" + \" title=\"Forward one day\"> &nbsp;\n",
      "</fieldset>\n",
      "</form>\n",
      "<table width=\"100%\"><tr><td><strong>Closest 5  observations near 40.05&deg;N, -106.04&deg;W</strong><br>40.05&deg;N, -106.04&deg;W (Elevation: N/A)</td>\n",
      "<td align=\"right\">Latest between <span class=\"date\">2022-05-03 06:00 UTC</span><br>and  <span class=\"date\">2022-05-04 06:00 UTC</span></td></tr></table><hr>\n",
      "<table class=\"gray_data_table\" cellspacing=\"2\" summary=\"Table of Raw Snowfall Observations near 40.05&deg;N, -106.04&deg;W, \" width=\"100%\">\n",
      "<caption><strong>Raw Snowfall Observations</strong></caption>\n",
      " <colgroup>\n",
      " <colgroup>\n",
      " <colgroup>\n",
      " <colgroup>\n",
      " <colgroup>\n",
      " <colgroup>\n",
      " <colgroup>\n",
      " <thead>\n",
      "  <tr>\n",
      "<th scope=\"col\">Station ID</th><th scope=\"col\">Name</th><th scope=\"col\">Elev.<br> (ft)</th><th scope=\"col\">Raw Snowfall<br> (in)</th><th scope=\"col\">Duration<br> (hours)</th><th scope=\"col\">Date (UTC)</th><th scope=\"col\">Distance</th></tr>\n",
      " </thead>\n",
      " <tbody>\n",
      "<tr><td class=\"desc\" title=\"(40.0071&deg;N, -105.8862&deg;W)\"><a href=\"/interactive/html/graph.html?units=0&amp;ey=2022&amp;em=5&amp;ed=6&amp;eh=6&amp;station=CO-GR-68\">CO-GR-68</a></td><td class=\"desc\">TABERNASH 2.7 NW, CO</td><td>8806</td><td>0.00</td><td>24</td><td>2022-05-03 13</td><td>8.7 mi ESE</td></tr>\n",
      "<tr><td class=\"desc\" title=\"(40.0375&deg;N, -106.203&deg;W)\"><a href=\"/interactive/html/graph.html?units=0&amp;ey=2022&amp;em=5&amp;ed=6&amp;eh=6&amp;station=WIFC2\">WIFC2</a></td><td class=\"desc\">WILLIAMS FORK DAM</td><td>7733</td><td>0.00</td><td>24</td><td>2022-05-03 14</td><td>8.7 mi W</td></tr>\n",
      "<tr><td class=\"desc\" title=\"(40.1186&deg;N, -105.8997&deg;W)\"><a href=\"/interactive/html/graph.html?units=0&amp;ey=2022&amp;em=5&amp;ed=6&amp;eh=6&amp;station=CO-GR-81\">CO-GR-81</a></td><td class=\"desc\">GRANBY 2.9 NE, CO</td><td>8041</td><td>0.00</td><td>24</td><td>2022-05-04 01</td><td>8.8 mi ENE</td></tr>\n",
      "<tr><td class=\"desc\" title=\"(40.0911&deg;N, -106.2&deg;W)\"><a href=\"/interactive/html/graph.html?units=0&amp;ey=2022&amp;em=5&amp;ed=6&amp;eh=6&amp;station=CO-GR-52\">CO-GR-52</a></td><td class=\"desc\">PARSHALL 3.0 NNW, CO</td><td>7904</td><td>0.00</td><td>24</td><td>2022-05-03 13</td><td>8.9 mi WNW</td></tr>\n",
      "<tr><td class=\"desc\" title=\"(40.0015&deg;N, -105.8725&deg;W)\"><a href=\"/interactive/html/graph.html?units=0&amp;ey=2022&amp;em=5&amp;ed=6&amp;eh=6&amp;station=CO-GR-53\">CO-GR-53</a></td><td class=\"desc\">TABERNASH 1.9 NW, CO</td><td>8579</td><td>0.00</td><td>24</td><td>2022-05-03 06</td><td>9.5 mi ESE</td></tr>\n",
      "</tbody></table>\n",
      "<hr>\n",
      "<table class=\"gray_data_table\" cellspacing=\"2\" summary=\"Table of Snow Depth Observations near 40.05&deg;N, -106.04&deg;W, \" width=\"100%\">\n",
      "<caption><strong>Snow Depth Observations</strong></caption>\n",
      " <colgroup>\n",
      " <colgroup>\n",
      " <colgroup>\n",
      " <colgroup>\n",
      " <colgroup>\n",
      " <colgroup>\n",
      " <thead>\n",
      "  <tr>\n",
      "<th scope=\"col\">Station ID</th><th scope=\"col\">Name</th><th scope=\"col\">Elev.<br> (ft)</th><th scope=\"col\">Snow Depth<br> (in)</th><th scope=\"col\">Date (UTC)</th><th scope=\"col\">Distance</th></tr>\n",
      " </thead>\n",
      " <tbody>\n",
      "<tr><td class=\"desc\" title=\"(40.0071&deg;N, -105.8862&deg;W)\"><a href=\"/interactive/html/graph.html?units=0&amp;ey=2022&amp;em=5&amp;ed=6&amp;eh=6&amp;station=CO-GR-68\">CO-GR-68</a></td><td class=\"desc\">TABERNASH 2.7 NW, CO</td><td>8806</td><td>0.00</td><td>2022-05-03 13</td><td>8.7 mi ESE</td></tr>\n",
      "<tr><td class=\"desc\" title=\"(40.0375&deg;N, -106.203&deg;W)\"><a href=\"/interactive/html/graph.html?units=0&amp;ey=2022&amp;em=5&amp;ed=6&amp;eh=6&amp;station=WIFC2\">WIFC2</a></td><td class=\"desc\">WILLIAMS FORK DAM</td><td>7733</td><td>0.00</td><td>2022-05-03 14</td><td>8.7 mi W</td></tr>\n",
      "<tr><td class=\"desc\" title=\"(40.0911&deg;N, -106.2&deg;W)\"><a href=\"/interactive/html/graph.html?units=0&amp;ey=2022&amp;em=5&amp;ed=6&amp;eh=6&amp;station=CO-GR-52\">CO-GR-52</a></td><td class=\"desc\">PARSHALL 3.0 NNW, CO</td><td>7904</td><td>0.00</td><td>2022-05-03 13</td><td>8.9 mi WNW</td></tr>\n",
      "<tr><td class=\"desc\" title=\"(40.2254&deg;N, -105.9198&deg;W)\"><a href=\"/interactive/html/graph.html?units=0&amp;ey=2022&amp;em=5&amp;ed=6&amp;eh=6&amp;station=SCSC2\">SCSC2</a></td><td class=\"desc\">STILLWATER CREEK</td><td>8793</td><td>0.00</td><td>2022-05-04 05</td><td>13.7 mi NE</td></tr>\n",
      "<tr><td class=\"desc\" title=\"(40.2082&deg;N, -105.8634&deg;W)\"><a href=\"/interactive/html/graph.html?units=0&amp;ey=2022&amp;em=5&amp;ed=6&amp;eh=6&amp;station=CO-GR-78\">CO-GR-78</a></td><td class=\"desc\">GRAND LAKE 3.7 SW, CO</td><td>8537</td><td>0.00</td><td>2022-05-03 13</td><td>14.4 mi NE</td></tr>\n",
      "</tbody></table>\n",
      "<hr>\n",
      "<table class=\"gray_data_table\" cellspacing=\"2\" summary=\"Table of Snow Water Equivalent Observations near 40.05&deg;N, -106.04&deg;W, \" width=\"100%\">\n",
      "<caption><strong>Snow Water Equivalent Observations</strong></caption>\n",
      " <colgroup>\n",
      " <colgroup>\n",
      " <colgroup>\n",
      " <colgroup>\n",
      " <colgroup>\n",
      " <colgroup>\n",
      " <thead>\n",
      "  <tr>\n",
      "<th scope=\"col\">Station ID</th><th scope=\"col\">Name</th><th scope=\"col\">Elev.<br> (ft)</th><th scope=\"col\">Snow Water Equivalent<br> (in)</th><th scope=\"col\">Date (UTC)</th><th scope=\"col\">Distance</th></tr>\n",
      " </thead>\n",
      " <tbody>\n",
      "<tr><td class=\"desc\" title=\"(40.2254&deg;N, -105.9198&deg;W)\"><a href=\"/interactive/html/graph.html?units=0&amp;ey=2022&amp;em=5&amp;ed=6&amp;eh=6&amp;station=SCSC2\">SCSC2</a></td><td class=\"desc\">STILLWATER CREEK</td><td>8793</td><td>0.00</td><td>2022-05-04 05</td><td>13.7 mi NE</td></tr>\n",
      "<tr><td class=\"desc\" title=\"(39.8687&deg;N, -105.8675&deg;W)\"><a href=\"/interactive/html/graph.html?units=0&amp;ey=2022&amp;em=5&amp;ed=6&amp;eh=6&amp;station=FCVC2\">FCVC2</a></td><td class=\"desc\">FOOL CREEK</td><td>11168</td><td>20.10</td><td>2022-05-04 03</td><td>15.5 mi SE</td></tr>\n",
      "<tr><td class=\"desc\" title=\"(39.7956&deg;N, -106.0273&deg;W)\"><a href=\"/interactive/html/graph.html?units=0&amp;ey=2022&amp;em=5&amp;ed=6&amp;eh=6&amp;station=MFKC2\">MFKC2</a></td><td class=\"desc\">MIDDLE FORK CAMP</td><td>8983</td><td>1.30</td><td>2022-05-04 04</td><td>17.6 mi S</td></tr>\n",
      "<tr><td class=\"desc\" title=\"(40.347&deg;N, -106.0943&deg;W)\"><a href=\"/interactive/html/graph.html?units=0&amp;ey=2022&amp;em=5&amp;ed=6&amp;eh=6&amp;station=WLLC2\">WLLC2</a></td><td class=\"desc\">WILLOW CREEK PASS</td><td>9600</td><td>14.20</td><td>2022-05-04 05</td><td>20.7 mi N</td></tr>\n",
      "<tr><td class=\"desc\" title=\"(39.7645&deg;N, -105.9062&deg;W)\"><a href=\"/interactive/html/graph.html?units=0&amp;ey=2022&amp;em=5&amp;ed=6&amp;eh=6&amp;station=JNPC2\">JNPC2</a></td><td class=\"desc\">JONES PASS</td><td>10482</td><td>10.90</td><td>2022-05-04 05</td><td>20.9 mi SSE</td></tr>\n",
      "</tbody></table>\n",
      "<hr>\n",
      "<table class=\"gray_data_table\" cellspacing=\"2\" summary=\"Table of Raw Precipitation Observations near 40.05&deg;N, -106.04&deg;W, \" width=\"100%\">\n",
      "<caption><strong>Raw Precipitation Observations</strong></caption>\n",
      " <colgroup>\n",
      " <colgroup>\n",
      " <colgroup>\n",
      " <colgroup>\n",
      " <colgroup>\n",
      " <colgroup>\n",
      " <colgroup>\n",
      " <thead>\n",
      "  <tr>\n",
      "<th scope=\"col\">Station ID</th><th scope=\"col\">Name</th><th scope=\"col\">Elev.<br> (ft)</th><th scope=\"col\">Raw Precipitation<br> (in)</th><th scope=\"col\">Duration<br> (hours)</th><th scope=\"col\">Date (UTC)</th><th scope=\"col\">Distance</th></tr>\n",
      " </thead>\n",
      " <tbody>\n",
      "<tr><td class=\"desc\" title=\"(40.1083&deg;N, -106.0036&deg;W)\"><a href=\"/interactive/html/graph.html?units=0&amp;ey=2022&amp;em=5&amp;ed=6&amp;eh=6&amp;station=CAWC2\">CAWC2</a></td><td class=\"desc\">COLORADO RVR BLW WINDY GAP</td><td>7822</td><td>0.03</td><td>24</td><td>2022-05-04 06</td><td>4.5 mi NNE</td></tr>\n",
      "<tr><td class=\"desc\" title=\"(40.136&deg;N, -106.1744&deg;W)\"><a href=\"/interactive/html/graph.html?units=0&amp;ey=2022&amp;em=5&amp;ed=6&amp;eh=6&amp;station=GRUC2\">GRUC2</a></td><td class=\"desc\">GROUSE MOUNTAIN</td><td>10013</td><td>0.00</td><td>1</td><td>2022-05-04 05</td><td>9.3 mi WNW</td></tr>\n",
      "<tr><td class=\"desc\" title=\"(39.9259&deg;N, -106.1391&deg;W)\"><a href=\"/interactive/html/graph.html?units=0&amp;ey=2022&amp;em=5&amp;ed=6&amp;eh=6&amp;station=CO-GR-86\">CO-GR-86</a></td><td class=\"desc\">PARSHALL 8.8 SSE, CO</td><td>8491</td><td>0.20</td><td>24</td><td>2022-05-03 15</td><td>10 mi SW</td></tr>\n",
      "<tr><td class=\"desc\" title=\"(39.8906&deg;N, -106.0367&deg;W)\"><a href=\"/interactive/html/graph.html?units=0&amp;ey=2022&amp;em=5&amp;ed=6&amp;eh=6&amp;station=KSEC2\">KSEC2</a></td><td class=\"desc\">KEYSER RIDGE</td><td>10190</td><td>0.00</td><td>1</td><td>2022-05-04 05</td><td>11 mi S</td></tr>\n",
      "<tr><td class=\"desc\" title=\"(39.8906&deg;N, -106.0367&deg;W)\"><a href=\"/interactive/html/graph.html?units=0&amp;ey=2022&amp;em=5&amp;ed=6&amp;eh=6&amp;station=KSEC2\">KSEC2</a></td><td class=\"desc\">KEYSER RIDGE</td><td>10190</td><td>0.00</td><td>24</td><td>2022-05-04 05</td><td>11 mi S</td></tr>\n",
      "</tbody></table>\n",
      "<br>\n",
      "<span style=\"color: white\">Page generated in 4.04889 seconds.</span><br>\n",
      "\t\t\t\t<br><br>\n",
      "\t\t\t\t<table align=\"center\" cellspacing=\"2\" cellpadding=\"2\" border=\"0\">\n",
      "\t\t\t\t\t<tr align=\"center\">\n",
      "\t\t\t\t\t\t<td>\n",
      "\t\t\t\t\t\t\tNOHRSC<br>\n",
      "\t\t\t\t\t\t\t<a href=\"/mission.html\">Mission Statement</a>\n",
      "\t\t\t\t\t\t\t&nbsp;|&nbsp;\n",
      "\t\t\t\t\t\t\t<a href=\"/contact.html\">Contact</a>\n",
      "\t\t\t\t\t\t</td>\n",
      "\t\t\t\t\t</tr>\n",
      "\t\t\t\t</table>\n",
      "\t\t\t\t<table width=\"100%\" cellspacing=\"0\" cellpadding=\"0\" border=\"0\">\n",
      "\t\t\t\t\t<tr>\n",
      "\t\t\t\t\t\t<td colspan=\"3\"><hr></td>\n",
      "\t\t\t\t\t</tr>\n",
      "\t\t\t\t\t<tr valign=\"top\"> \n",
      "\t\t\t\t\t\t<td align=\"left\" class=\"gray\">\n",
      "\t\t\t\t\t\t\t<br>\n",
      "\t\t\t\t\t\t\t<a href=\"https://www.weather.gov\"><span class=\"gray\">National Weather Service</span></a><br>\n",
      "\t\t\t\t\t\t\tNational Operational Hydrologic Remote Sensing Center<br>\n",
      "                                                        <a href=\"https://water.noaa.gov\"><span class=\"gray\">Office of Water Prediction</span></a><br>\n",
      "\t\t\t\t\t\t\t1735 Lake Drive W.<br>\n",
      "\t\t\t\t\t\t\tChanhassen, MN 55317<br>\n",
      "\t\t\t\t\t\t\t<br>\n",
      "\t\t\t\t\t\t</td>\n",
      "\t\t\t\t\t\t<td align=\"right\">\n",
      "\t\t\t\t\t\t\t<a href=\"/\"><img src=\"/images/nohrsc.png\" alt=\"NOHRSC homepage\" border=0></a>\n",
      "\t\t\t\t\t\t</td>\n",
      "\t\t\t\t\t</tr>\n",
      "\t\t\t\t\t<tr valign=\"top\">\n",
      "\t\t\t\t\t\t<td align=\"left\" class=\"gray\">\n",
      "\t\t\t\t\t\t\t<a href=\"/contact.html\"><span class=\"gray\">Contact NOHRSC</span></a><br>\n",
      "\t\t\t\t\t\t\t<a href=\"https://www.weather.gov/glossary/\"><span class=\"gray\">Glossary</span></a><br>\n",
      "\t\t\t\t\t\t\t<a href=\"https://www.weather.gov/credits.php\"><span class=\"gray\">Credits</span></a><br>\n",
      "\t\t\t\t\t\t\t<a href=\"https://www.cio.noaa.gov/Policy_Programs/info_quality.html\"><span class=\"gray\">Information Quality</span></a><br>\n",
      "Page last modified: Nov 14, 2022 - cloud<br>\n",
      "\t\t\t\t\t\t</td>\n",
      "\t\t\t\t\t\t<td align=\"right\" class=\"gray\">\n",
      "\t\t\t\t\t\t\t<a href=\"https://www.weather.gov/admin.php\"><span class=\"gray\">About Us</span></a><br>\n",
      "\t\t\t\t\t\t\t<a href=\"https://www.weather.gov/disclaimer.php\"><span class=\"gray\">Disclaimer</span></a><br>\n",
      "\t\t\t\t\t\t\t<a href=\"https://www.weather.gov/privacy.php\"><span class=\"gray\">Privacy Policy</span></a><br>\n",
      "\t\t\t\t\t\t\t<a href=\"https://www.rdc.noaa.gov/~foia/\"><span class=\"gray\">FOIA</span></a><br>\n",
      "\t\t\t\t\t\t\t<a href=\"https://www.weather.gov/careers.php\"><span class=\"gray\">Career Opportunities</span></a><br>\n",
      "\t\t\t\t\t\t</td>\n",
      "\t\t\t\t\t</tr>\n",
      "\t\t\t\t</table>\n",
      "\t\t\t</td>\n",
      "\t\t</tr>\n",
      "\t</table>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "Container div not found\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# First Python script in Geoweaver\n",
    "import os\n",
    "import urllib.request, urllib.error, urllib.parse\n",
    "import sys\n",
    "\n",
    "print(sys.path)\n",
    "\n",
    "try:\n",
    "    from BeautifulSoup import BeautifulSoup\n",
    "except ImportError:\n",
    "    from bs4 import BeautifulSoup\n",
    "\n",
    "nohrsc_url_format_string = \"https://www.nohrsc.noaa.gov/nearest/index.html?city={lat}%2C{lon}&county=&l=5&u=e&y={year}&m={month}&d={day}\"\n",
    "\n",
    "test_noaa_query_url = nohrsc_url_format_string.format(lat=40.05352381745094, lon=-106.04027196859343, year=2022, month=5, day=4)\n",
    "\n",
    "print(test_noaa_query_url)\n",
    "\n",
    "response = urllib.request.urlopen(test_noaa_query_url)\n",
    "webContent = response.read().decode('UTF-8')\n",
    "\n",
    "print(webContent)\n",
    "\n",
    "parsed_html = BeautifulSoup(webContent)\n",
    "container_div = parsed_html.body.find('div', attrs={'class':'container'})\n",
    "\n",
    "if container_div is not None:\n",
    "    print(container_div.text)\n",
    "else:\n",
    "    print(\"Container div not found\")\n",
    "\n",
    "print(container_div)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee2035e",
   "metadata": {},
   "source": [
    "We automate the process of accessing and parsing NOAA's snow data using BeautifulSoup. By constructing a query URL based on user-defined location and date parameters, we automate the process of fetching web content and parsing HTML to extract pertinent information. The above script enhances efficiency in obtaining snow data, offering a user-friendly approach for various analyses or applications without the need for technical expertise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afc5f94",
   "metadata": {},
   "source": [
    "# DEM Dataset\n",
    "\n",
    "## Introduction to DEM (Digital Elevation Model):\n",
    "A Digital Elevation Model (DEM) is a digital representation of the topography of a surface, such as the Earth's terrain or the surface of another celestial body. It consists of a grid of elevation values, where each cell in the grid represents the elevation at a specific location. DEMs are widely used in various fields, including geography, geology, hydrology, environmental modeling, urban planning, and 3D visualization.\n",
    "\n",
    "## Characteristics\n",
    "\n",
    "- **Spatial Resolution**: DEMs can vary in spatial resolution, ranging from coarse resolution global datasets to high-resolution local datasets. Higher spatial resolution DEMs provide more detailed information about the terrain.\n",
    "  \n",
    "- **Accuracy**: The accuracy of DEMs depends on the source data and the methods used for their generation. High-quality DEMs are crucial for accurate analysis and decision-making in applications such as flood modeling, terrain navigation, and infrastructure planning.\n",
    "  \n",
    "- **Coverage**: DEMs can cover different geographic extents, from local areas to entire continents or even the entire globe. The coverage of a DEM determines its utility for specific applications.\n",
    "  \n",
    "- **Data Format**: DEM data is typically stored in raster formats such as GeoTIFF, ASCII grid, or Esri GRID. DEM data is typically stored in raster formats such as GeoTIFF, ASCII grid, or Esri GRID.\n",
    "\n",
    "DEM data is typically stored in raster formats such as GeoTIFF, ASCII grid, or Esri GRID. DEM data is typically stored in raster formats such as GeoTIFF, ASCII grid, or Esri GRID. Additional information such as coordinate system, spatial resolution, and metadata may also be included in the data file.\n",
    "\n",
    "\n",
    "<img src=\"../img/DEM/elevation_map.png\" alt=\"Elevation Map\" height=\"300\" width=\"300\"/>\n",
    "<img src=\"../img/DEM/aspect_map.png\" alt=\"Aspect Map\" height=\"300\" width=\"300\">\n",
    "\n",
    "<img src=\"../img/DEM/northness_map.png\" alt=\"Nothness Map\" height=\"300\" width=\"300\">\n",
    "<img src=\"../img/DEM/eastness_map.png\" alt=\"Eastness Map\" height=\"300\" width=\"300\">\n",
    "\n",
    "\n",
    "## Data Sources and Acquisition:\n",
    "\n",
    "#### Satellite Imagery:\n",
    "DEMs can be derived from satellite imagery using techniques such as stereo photogrammetry or interferometry.\n",
    "\n",
    "#### Aerial LiDAR (Light Detection and Ranging):\n",
    "LiDAR data collected from aircraft can produce high-resolution DEMs with accurate elevation information.\n",
    "\n",
    "#### Topographic Surveys:\n",
    "Ground-based surveys using total stations or GPS equipment can also be used to generate DEMs for smaller areas with high precision.\n",
    "\n",
    "## Applications:\n",
    "\n",
    "- Terrain Analysis for Infrastructure Development\n",
    "- Environmental Impact Assessment\n",
    "- Geological Mapping and Exploration\n",
    "- Disaster Risk Reduction\n",
    "- Climate Change Modeling\n",
    "- Ecological and Habitat Modeling\n",
    "\n",
    "# DEM Data Download:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0e8e426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "western_df.head() =     Latitude  Longitude  x  y   Elevation     Slope     Aspect   Curvature  \\\n",
      "0      49.0   -125.000  0  0   15.124211  0.470627  272.35254  3624.44560   \n",
      "1      49.0   -124.964  1  0  136.762280  0.454659  284.84660  1261.81840   \n",
      "2      49.0   -124.928  2  0  258.745100  0.446243  282.81650 -1763.61730   \n",
      "3      49.0   -124.892  3  0  387.150480  0.281288    6.37222 -2461.73140   \n",
      "4      49.0   -124.856  4  0  213.531710  0.405632   30.24500  -511.48447   \n",
      "\n",
      "   Northness  Eastness  \n",
      "0   0.041025  0.784977  \n",
      "1   0.250835  0.768424  \n",
      "2   0.218295  0.772784  \n",
      "3   0.782300 -0.110535  \n",
      "4   0.712497 -0.466602  \n",
      "stations_file_df.head() =      stationTriplet stationId stateCode networkCode                    name  \\\n",
      "0      ABY:CA:SNOW       ABY        CA        SNOW                   Abbey   \n",
      "1     0010:ID:COOP      0010        ID        COOP  Aberdeen Experimnt Stn   \n",
      "2     0041:NM:COOP      0041        NM        COOP             Abiquiu Dam   \n",
      "3  08108010:NM:BOR  08108010        NM         BOR       Abiquiu Reservoir   \n",
      "4    13E19:ID:SNOW     13E19        ID        SNOW           Above Gilmore   \n",
      "\n",
      "  dcoCode  countyName           huc  elevation  latitude  longitude  \\\n",
      "0      UN      Plumas  1.802012e+11     5650.0  39.95500 -120.53800   \n",
      "1      ID     Bingham  1.704021e+11     4410.0  42.95000 -112.83333   \n",
      "2      UN  Rio Arriba  1.302010e+11     6380.0  36.23333 -106.43333   \n",
      "3      CO  Rio Arriba  1.302010e+11     6180.0  36.23700 -106.42912   \n",
      "4      ID       Lemhi  1.706020e+11     8289.0  44.45615 -113.30097   \n",
      "\n",
      "   dataTimeZone  pedonCode shefId              beginDate     endDate  \n",
      "0           NaN        NaN    NaN  1963-02-01 00:00:00.0  2100-01-01  \n",
      "1           NaN        NaN  ABDI1  1914-01-01 00:00:00.0  2100-01-01  \n",
      "2           NaN        NaN  ABIN5  1957-01-01 00:00:00.0  2100-01-01  \n",
      "3           NaN        NaN    NaN  1964-09-01 00:00:00.0  2100-01-01  \n",
      "4           NaN        NaN  ABGI1  1961-01-01 00:00:00.0  2100-01-01  \n"
     ]
    }
   ],
   "source": [
    "# Load dependencies\n",
    "import geopandas as gpd\n",
    "import json\n",
    "import geojson\n",
    "from pystac_client import Client\n",
    "import planetary_computer\n",
    "import xarray\n",
    "import rioxarray\n",
    "import xrspatial\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pyproj import Proj, transform\n",
    "import os\n",
    "import sys, traceback\n",
    "import requests\n",
    "\n",
    "home_dir = os.path.expanduser('~')\n",
    "work_dir = f\"{home_dir}/gridmet_test_run\"\n",
    "snowcast_github_dir = f\"{home_dir}/Documents/GitHub/SnowCast/\"\n",
    "\n",
    "#exit() # this process no longer need to execute, we need to make Geoweaver to specify which process doesn't need to run\n",
    "\n",
    "# user-defined paths for data-access\n",
    "data_dir = f'{snowcast_github_dir}data/'\n",
    "gridcells_file = data_dir+'snowcast_provided/grid_cells_eval.geojson'\n",
    "stations_file = f\"{work_dir}/all_snotel_cdec_stations_active_in_westus.csv\"\n",
    "gridcells_outfile = data_dir+'terrain/gridcells_terrainData_eval.csv'\n",
    "stations_outfile = f\"{work_dir}/training_all_active_snotel_station_list_elevation.csv_terrain_4km_grid_shift.csv\"\n",
    "\n",
    "\n",
    "def get_planetary_client():\n",
    "  #requests.get('https://planetarycomputer.microsoft.com/api/stac/v1')\n",
    "\n",
    "  # setup client for handshaking and data-access\n",
    "  print(\"setup planetary computer client\")\n",
    "  client = Client.open(\"https://planetarycomputer.microsoft.com/api/stac/v1\",ignore_conformance=True)\n",
    "  \n",
    "  return client\n",
    "\n",
    "def prepareGridCellTerrain():\n",
    "  client = get_planetary_client()\n",
    "  # Load metadata\n",
    "  gridcellsGPD = gpd.read_file(gridcells_file)\n",
    "  gridcells = geojson.load(open(gridcells_file))\n",
    "  stations = pd.read_csv(stations_file)\n",
    "\n",
    "  # instantiate output panda dataframes\n",
    "  df_gridcells = df = pd.DataFrame(columns=(\n",
    "    \"Longitude [deg]\",\"Latitude [deg]\",\n",
    "    \"Elevation [m]\",\"Aspect [deg]\",\n",
    "    \"Curvature [ratio]\",\"Slope [deg]\",\n",
    "    \"Eastness [unitCirc.]\",\"Northness [unitCirc.]\"))\n",
    "  # instantiate output panda dataframes\n",
    "  # Calculate gridcell characteristics using Copernicus DEM data\n",
    "  print(\"Prepare GridCell Terrain data\")\n",
    "  for idx,cell in enumerate(gridcells['features']):\n",
    "      print(\"Processing grid \", idx)\n",
    "      search = client.search(\n",
    "          collections=[\"cop-dem-glo-30\"],\n",
    "          intersects={\"type\":\"Polygon\", \"coordinates\":cell['geometry']['coordinates']},\n",
    "      )\n",
    "      items = list(search.get_items())\n",
    "      print(\"==> Searched items: \", len(items))\n",
    "\n",
    "      cropped_data = None\n",
    "      try:\n",
    "          signed_asset = planetary_computer.sign(items[0].assets[\"data\"])\n",
    "          data = (\n",
    "              #xarray.open_rasterio(signed_asset.href)\n",
    "              xarray.open_rasterio(signed_asset.href)\n",
    "              .squeeze()\n",
    "              .drop(\"band\")\n",
    "              .coarsen({\"y\": 1, \"x\": 1})\n",
    "              .mean()\n",
    "          )\n",
    "          cropped_data = data.rio.clip(gridcellsGPD['geometry'][idx:idx+1])\n",
    "      except:\n",
    "          signed_asset = planetary_computer.sign(items[1].assets[\"data\"])\n",
    "          data = (\n",
    "              xarray.open_rasterio(signed_asset.href)\n",
    "              .squeeze()\n",
    "              .drop(\"band\")\n",
    "              .coarsen({\"y\": 1, \"x\": 1})\n",
    "              .mean()\n",
    "          )\n",
    "          cropped_data = data.rio.clip(gridcellsGPD['geometry'][idx:idx+1])\n",
    "\n",
    "      # calculate lat/long of center of gridcell\n",
    "      longitude = np.unique(np.ravel(cell['geometry']['coordinates'])[0::2]).mean()\n",
    "      latitude = np.unique(np.ravel(cell['geometry']['coordinates'])[1::2]).mean()\n",
    "\n",
    "      print(\"reproject data to EPSG:32612\")\n",
    "      # reproject the cropped dem data\n",
    "      cropped_data = cropped_data.rio.reproject(\"EPSG:32612\")\n",
    "\n",
    "      # Mean elevation of gridcell\n",
    "      mean_elev = cropped_data.mean().values\n",
    "      print(\"Elevation: \", mean_elev)\n",
    "\n",
    "      # Calculate directional components\n",
    "      aspect = xrspatial.aspect(cropped_data)\n",
    "      aspect_xcomp = np.nansum(np.cos(aspect.values*(np.pi/180)))\n",
    "      aspect_ycomp = np.nansum(np.sin(aspect.values*(np.pi/180)))\n",
    "      mean_aspect = np.arctan2(aspect_ycomp,aspect_xcomp)*(180/np.pi)\n",
    "      if mean_aspect < 0:\n",
    "          mean_aspect = 360 + mean_aspect\n",
    "      print(\"Aspect: \", mean_aspect)\n",
    "      mean_eastness = np.cos(mean_aspect*(np.pi/180))\n",
    "      mean_northness = np.sin(mean_aspect*(np.pi/180))\n",
    "      print(\"Eastness: \", mean_eastness)\n",
    "      print(\"Northness: \", mean_northness)\n",
    "\n",
    "      # Positive curvature = upward convex\n",
    "      curvature = xrspatial.curvature(cropped_data)\n",
    "      mean_curvature = curvature.mean().values\n",
    "      print(\"Curvature: \", mean_curvature)\n",
    "\n",
    "      # Calculate mean slope\n",
    "      slope = xrspatial.slope(cropped_data)\n",
    "      mean_slope = slope.mean().values\n",
    "      print(\"Slope: \", mean_slope)\n",
    "\n",
    "      # Fill pandas dataframe\n",
    "      df_gridcells.loc[idx] = [longitude,latitude,\n",
    "                               mean_elev,mean_aspect,\n",
    "                               mean_curvature,mean_slope,\n",
    "                               mean_eastness,mean_northness]\n",
    "\n",
    "  # Save output data into csv format\n",
    "  df_gridcells.set_index(gridcellsGPD['cell_id'][0:idx+1],inplace=True)\n",
    "  df_gridcells.to_csv(gridcells_outfile)\n",
    "\n",
    "def prepareStationTerrain():\n",
    "  client = get_planetary_client()\n",
    "  \n",
    "  df_station = pd.DataFrame(columns=(\"Longitude [deg]\",\"Latitude [deg]\",\n",
    "                                     \"Elevation [m]\",\"Elevation_30 [m]\",\"Elevation_1000 [m]\",\n",
    "                                     \"Aspect_30 [deg]\",\"Aspect_1000 [deg]\",\n",
    "                                     \"Curvature_30 [ratio]\",\"Curvature_1000 [ratio]\",\n",
    "                                     \"Slope_30 [deg]\",\"Slope_1000 [deg]\",\n",
    "                                     \"Eastness_30 [unitCirc.]\",\"Northness_30 [unitCirc.]\",\n",
    "                                     \"Eastness_1000 [unitCirc.]\",\"Northness_1000 [unitCirc.]\"))\n",
    "  \n",
    "  stations_df = pd.read_csv(stations_file)\n",
    "  print(stations_df.head())\n",
    "  # Calculate terrain characteristics of stations, and surrounding regions using COP 30\n",
    "  for idx,station in stations_df.iterrows():\n",
    "      search = client.search(\n",
    "          collections=[\"cop-dem-glo-30\"],\n",
    "          intersects={\n",
    "            \"type\": \"Point\", \n",
    "            \"coordinates\": [\n",
    "              stations_df['lon'],\n",
    "              stations_df['lat']\n",
    "            ]\n",
    "          },\n",
    "      )\n",
    "      items = list(search.get_items())\n",
    "      print(f\"Returned {len(items)} items\")\n",
    "\n",
    "      try:\n",
    "          signed_asset = planetary_computer.sign(items[0].assets[\"data\"])\n",
    "          data = (\n",
    "              xarray.open_rasterio(signed_asset.href)\n",
    "              .squeeze()\n",
    "              .drop(\"band\")\n",
    "              .coarsen({\"y\": 1, \"x\": 1})\n",
    "              .mean()\n",
    "          )\n",
    "          xdiff = np.abs(data.x-stations_df['lon'])\n",
    "          ydiff = np.abs(data.y-stations_df['lat'])\n",
    "          xdiff = np.where(xdiff == xdiff.min())[0][0]\n",
    "          ydiff = np.where(ydiff == ydiff.min())[0][0]\n",
    "          data = data[ydiff-33:ydiff+33,xdiff-33:xdiff+33].rio.reproject(\"EPSG:32612\")\n",
    "      except:\n",
    "          traceback.print_exc(file=sys.stdout)\n",
    "          signed_asset = planetary_computer.sign(items[1].assets[\"data\"])\n",
    "          data = (\n",
    "              xarray.open_rasterio(signed_asset.href)\n",
    "              .squeeze()\n",
    "              .drop(\"band\")\n",
    "              .coarsen({\"y\": 1, \"x\": 1})\n",
    "              .mean()\n",
    "          )\n",
    "          xdiff = np.abs(data.x-stations_df['lon'])\n",
    "          ydiff = np.abs(data.y-stations_df['lat'])\n",
    "          xdiff = np.where(xdiff == xdiff.min())[0][0]\n",
    "          ydiff = np.where(ydiff == ydiff.min())[0][0]\n",
    "          data = data[ydiff-33:ydiff+33,xdiff-33:xdiff+33].rio.reproject(\"EPSG:32612\")\n",
    "\n",
    "      # Reproject the station data to better include only 1000m surrounding area\n",
    "      inProj = Proj(init='epsg:4326')\n",
    "      outProj = Proj(init='epsg:32612')\n",
    "      new_x,new_y = transform(inProj,outProj,\n",
    "                              stations_df['lon'],\n",
    "                              stations_df['lat'])\n",
    "\n",
    "      # Calculate elevation of station and surroundings\n",
    "      mean_elevation = data.mean().values\n",
    "      elevation = data.sel(x=new_x,y=new_y,method='nearest')\n",
    "      print(elevation.values)\n",
    "\n",
    "      # Calcuate directional components\n",
    "      aspect = xrspatial.aspect(data)\n",
    "      aspect_xcomp = np.nansum(np.cos(aspect.values*(np.pi/180)))\n",
    "      aspect_ycomp = np.nansum(np.sin(aspect.values*(np.pi/180)))\n",
    "      mean_aspect = np.arctan2(aspect_ycomp,aspect_xcomp)*(180/np.pi)\n",
    "      if mean_aspect < 0:\n",
    "          mean_aspect = 360 + mean_aspect\n",
    "      aspect = aspect.sel(x=new_x,y=new_y,method='nearest')\n",
    "      eastness = np.cos(aspect*(np.pi/180))\n",
    "      northness = np.sin(aspect*(np.pi/180))\n",
    "      mean_eastness = np.cos(mean_aspect*(np.pi/180))\n",
    "      mean_northness = np.sin(mean_aspect*(np.pi/180))\n",
    "\n",
    "      # Positive curvature = upward convex\n",
    "      curvature = xrspatial.curvature(data)\n",
    "      mean_curvature = curvature.mean().values\n",
    "      curvature = curvature.sel(x=new_x,y=new_y,method='nearest')\n",
    "      print(curvature.values)\n",
    "\n",
    "      # Calculate slope\n",
    "      slope = xrspatial.slope(data)\n",
    "      mean_slope = slope.mean().values\n",
    "      slope = slope.sel(x=new_x,y=new_y,method='nearest')\n",
    "      print(slope.values)\n",
    "\n",
    "      # Fill pandas dataframe\n",
    "      df_station.loc[idx] = [stations_df['lon'],\n",
    "                             stations_df['lat'],\n",
    "                             station['elevation_m'],\n",
    "                             elevation.values,mean_elevation,\n",
    "                             aspect.values,mean_aspect,\n",
    "                             curvature.values,mean_curvature,\n",
    "                             slope.values,mean_slope,\n",
    "                             eastness.values,northness.values,\n",
    "                             mean_eastness,mean_northness]\n",
    "\n",
    "  # Save output data into CSV format\n",
    "  df_station.set_index(stations_df['station_name'][0:idx+1],inplace=True)\n",
    "  df_station.to_csv(stations_outfile)\n",
    "\n",
    "\n",
    "def add_more_points_to_the_gridcells():\n",
    "  # check how many points are in the current grid_cell json\n",
    "  station_cell_mapping = f\"{work_dir}/station_cell_mapping.csv\"\n",
    "  current_grid_df = pd.read_csv(station_cell_mapping)\n",
    "  \n",
    "  print(current_grid_df.columns)\n",
    "  print(current_grid_df.shape)\n",
    "  \n",
    "  western_us_coords = f'{work_dir}/dem_file.tif.csv'\n",
    "  dem_df = pd.read_csv(western_us_coords)\n",
    "  print(dem_df.head())\n",
    "  print(dem_df.shape)\n",
    "  filtered_df = dem_df[dem_df['Elevation'] > 20]  # choose samples from points higher than 20 meters\n",
    "\n",
    "  # Randomly choose 700 rows from the filtered DataFrame\n",
    "  random_rows = filtered_df.sample(n=700)\n",
    "  random_rows = random_rows[[\"Latitude\", \"Longitude\"]]\n",
    "  random_rows.rename(columns={\n",
    "    'Latitude': 'lat', \n",
    "    'Longitude': 'lon'\n",
    "  }, inplace=True)\n",
    "  previous_cells = current_grid_df[[\"lat\", \"lon\"]]\n",
    "  result_df = previous_cells.append(random_rows, ignore_index=True)\n",
    "  print(result_df.shape)\n",
    "  result_df.to_csv(f\"{work_dir}/new_training_points_with_random_dem_locations.csv\")\n",
    "  print(f\"New training points are saved to {work_dir}/new_training_points_with_random_dem_locations.csv\")\n",
    "  \n",
    "  \n",
    "  \n",
    "  # find the random points that are on land from the dem.json\n",
    "  \n",
    "  # merge the grid_cell.json with the new dem points into a new grid_cell.json\n",
    "  \n",
    "def find_closest_index(target_latitude, target_longitude, lat_grid, lon_grid):\n",
    "    \"\"\"\n",
    "    Find the closest grid point indices for a target latitude and longitude.\n",
    "\n",
    "    Parameters:\n",
    "        target_latitude (float): Target latitude.\n",
    "        target_longitude (float): Target longitude.\n",
    "        lat_grid (numpy.ndarray): Array of latitude values.\n",
    "        lon_grid (numpy.ndarray): Array of longitude values.\n",
    "\n",
    "    Returns:\n",
    "        int: Latitude index.\n",
    "        int: Longitude index.\n",
    "        float: Closest latitude value.\n",
    "        float: Closest longitude value.\n",
    "    \"\"\"\n",
    "    lat_diff = np.float64(np.abs(lat_grid - target_latitude))\n",
    "    lon_diff = np.float64(np.abs(lon_grid - target_longitude))\n",
    "    row_idx = np.argmin(lat_diff + lon_diff)\n",
    "    return row_idx\n",
    "  \n",
    "  \n",
    "def read_terrain_from_dem_csv():\n",
    "  western_us_coords = f'{work_dir}/dem_all.csv'\n",
    "  western_df = pd.read_csv(western_us_coords)\n",
    "  print(\"western_df.head() = \", western_df.head())\n",
    "  \n",
    "  stations_file_df = pd.read_csv(stations_file)\n",
    "  print(\"stations_file_df.head() = \", stations_file_df.head())\n",
    "  \n",
    "  def find_closest_dem_row(row, western_df):\n",
    "    #print(row)\n",
    "    row_idx = find_closest_index(\n",
    "      row[\"latitude\"],\n",
    "      row[\"longitude\"],\n",
    "      western_df[\"Latitude\"], \n",
    "      western_df[\"Longitude\"]\n",
    "    )\n",
    "    dem_row = western_df.iloc[row_idx]\n",
    "    new_row = pd.concat([row, dem_row], axis=0)\n",
    "    return new_row\n",
    "  \n",
    "  stations_file_df = stations_file_df.apply(find_closest_dem_row, args=(western_df,), axis=1)\n",
    "  stations_file_df.to_csv(stations_outfile, index=False)\n",
    "  \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  try:\n",
    "    read_terrain_from_dem_csv()\n",
    "  except:\n",
    "    traceback.print_exc(file=sys.stdout)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb5bf61",
   "metadata": {},
   "source": [
    "In our geospatial data processing workflow, we utilize various libraries to analyze terrain characteristics for the SnowCast project. We calculate attributes like elevation, aspect, curvature, slope, eastness, and northness for grid cells and station locations. Our process involves accessing Copernicus DEM data and leveraging the Planetary Computer service. Through this analysis, we contribute to a broader understanding of the geographic region under study."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
