{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a19b1c84c1e62af1",
   "metadata": {},
   "source": [
    "# Training and Testing Dataset Overview\n",
    "\n",
    "# Introduction\n",
    "In the realm of environmental research and forecasting, access to reliable and comprehensive datasets is paramount. Four such indispensable sources are gridMET, AMSR, MODIS, and SNOTEL. Each dataset offers unique insights into various aspects of Earth's climate and terrain, contributing significantly to our understanding of environmental dynamics. These datasets serve as the cornerstone for numerous applications, including weather forecasting, ecological modeling, and climate change research. In our **snowcast_wormhole** workflow, we leverage the richness of these datasets to enhance the accuracy and robustness. Let's embark on a detailed exploration of these invaluable data sources.\n",
    "\n",
    "\n",
    "# gridMET Dataset\n",
    "\n",
    "## Introduction\n",
    "gridMET is like having a weather wizard at your fingertips! It's a dataset packed with daily high-spatial resolution (~4-km, 1/24th degree) surface meteorological data covering the contiguous US, spanning from 1979 up to yesterday. It even extends its reach to cover southern British Columbia in real-time products. This dataset provides vital insights into weather patterns, aiding various industries and scientific endeavors.\n",
    "\n",
    "## Insights\n",
    "\n",
    "* It offers a fascinating glimpse into historical weather patterns, allowing users to delve as far back as 1979.\n",
    "* The dataset provides an extensive array of information, including maximum and minimum temperatures, precipitation, radiation, wind velocity, and various other meteorological variables.xx\n",
    "* Scientists and modelers find it invaluable for a myriad of purposes, such as ecological research, agricultural strategizing, hydrological modeling, and beyond.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"../img/gridMET/tmmn-map.png\" alt=\"air_temperature_tmmn Map\" height=\"250\" width=\"250\"/>\n",
    "\n",
    "<img src=\"../img/gridMET/tmmx_map.png\" alt=\"air_temperature_tmmx Map\" height=\"250\" width=\"250\"/>\n",
    "\n",
    "<img src=\"../img/gridMET/evapotranspiration_map.png\" alt=\"potential_evapotranspiration Map\" height=\"250\" width=\"250\"/>\n",
    "\n",
    "<img src=\"../img/gridMET/mean_vapor_pressure_deficit_map.png\" alt=\"mean_vapor_pressure_deficit\"  height=\"250\" width=\"250\"/>\n",
    "\n",
    "<img src=\"../img/gridMET/relative_humidity_rmax_map.png\" alt=\"relative_humidity_rmax map\" height=\"250\" width=\"250\"/>\n",
    "\n",
    "<img src=\"../img/gridMET/relative_humidity_rmin_map.png\" alt=\"relative_humidity_rmin Map\" height=\"250\" width=\"250\"/>\n",
    "\n",
    "<img src=\"../img/gridMET/precipitation_amount.png\" alt=\"precipitation_amount Map\" height=\"250\" width=\"250\"/>\n",
    "\n",
    "<img src=\"../img/gridMET/wind_speed_map.png\" alt=\"wind_speed Map\" height=\"250\" width=\"250\"/>\n",
    "\n",
    "## Characteristics\n",
    "\n",
    "- **Spatial Resolution**: GridMET provides data at a high spatial resolution, typically around 4 kilometers.\n",
    "  \n",
    "- **Temporal Resolution**: The dataset offers data at a daily time step, allowing access to meteorological data for each day.\n",
    "  \n",
    "- **Variables**: GridMET includes meteorological variables such as temperature, precipitation, humidity, wind speed, and solar radiation.\n",
    "  \n",
    "- **Coverage**: The dataset covers the contiguous United States, providing comprehensive meteorological data for this region.\n",
    "  \n",
    "- **Quality**: Data is derived from multiple sources including weather station observations, satellite data, and meteorological models, and is quality-controlled.\n",
    "  \n",
    "- **Long-term Availability**: GridMET provides data spanning several decades, enabling analysis of historical meteorological trends and patterns.\n",
    "\n",
    "## Data Format:\n",
    "\n",
    "GRIDMET data is typically available in common file formats such as NetCDF (Network Common Data Form) or ASCII (plain text) format. NetCDF is widely used for multidimensional scientific data and provides efficient storage and access to large datasets. ASCII format offers simplicity and compatibility with various software tools for data analysis and visualization.\n",
    "\n",
    "## Data Sources and Acquisition:\n",
    "\n",
    "#### Satellite Data:\n",
    "GRIDMET utilizes satellite data from different sources such as the Geostationary Operational Environmental Satellite (GOES) and the Moderate Resolution Imaging Spectroradiometer (MODIS). These satellite observations provide valuable information on temperature, precipitation, humidity, and other atmospheric variables.\n",
    "\n",
    "#### Ground-Based Observations:\n",
    "The dataset incorporates ground-based weather station observations from various networks such as the National Weather Service's Cooperative Observer Program (COOP), the Automated Surface Observing System (ASOS), and the Automated Weather Data Network (AWDN). These observations help in validating and enhancing the accuracy of the dataset.\n",
    "\n",
    "#### Meteorological Models:\n",
    "gridMET also integrates data from numerical weather prediction models like the North American Mesoscale Forecast System (NAM) and the Weather Research and Forecasting (WRF) model. These models provide forecasts and simulations of meteorological variables which are then blended with observed data to create a more complete dataset.\n",
    "\n",
    "## Applications:\n",
    "\n",
    "- Climate research and modeling\n",
    "- Agriculture and crop management\n",
    "- Hydrology and water resource management\n",
    "- Renewable energy assessment\n",
    "- Disaster management and risk assessment\n",
    "- Ecological and environmental studies\n",
    "\n",
    "For more details and updates on GridMET visit this page https://www.climatologylab.org/gridmet.html\n",
    "\n",
    "# gridMET Data Download:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "383cbbb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading http://www.northwestknowledge.net/metdata/data/tmmn_2020.nc\n",
      "downloading http://www.northwestknowledge.net/metdata/data/tmmn_2021.nc\n",
      "downloading http://www.northwestknowledge.net/metdata/data/tmmx_2020.nc\n",
      "downloading http://www.northwestknowledge.net/metdata/data/tmmx_2021.nc\n",
      "downloading http://www.northwestknowledge.net/metdata/data/pr_2020.nc\n",
      "downloading http://www.northwestknowledge.net/metdata/data/pr_2021.nc\n",
      "downloading http://www.northwestknowledge.net/metdata/data/vpd_2020.nc\n",
      "downloading http://www.northwestknowledge.net/metdata/data/vpd_2021.nc\n",
      "downloading http://www.northwestknowledge.net/metdata/data/etr_2020.nc\n",
      "downloading http://www.northwestknowledge.net/metdata/data/etr_2021.nc\n",
      "downloading http://www.northwestknowledge.net/metdata/data/rmax_2020.nc\n",
      "downloading http://www.northwestknowledge.net/metdata/data/rmax_2021.nc\n",
      "downloading http://www.northwestknowledge.net/metdata/data/rmin_2020.nc\n",
      "downloading http://www.northwestknowledge.net/metdata/data/rmin_2021.nc\n",
      "downloading http://www.northwestknowledge.net/metdata/data/vs_2020.nc\n",
      "downloading http://www.northwestknowledge.net/metdata/data/vs_2021.nc\n",
      "reading values from /Users/meghana/gridmet_test_run/gridmet_climatology/rmin_2021.nc\n",
      "['relative_humidity']\n",
      "The file '/Users/meghana/gridmet_test_run/gridmet_climatology/rmin_2021.csv' exists.\n",
      "reading values from /Users/meghana/gridmet_test_run/gridmet_climatology/tmmn_2021.nc\n",
      "['air_temperature']\n",
      "The file '/Users/meghana/gridmet_test_run/gridmet_climatology/tmmn_2021.csv' exists.\n",
      "reading values from /Users/meghana/gridmet_test_run/gridmet_climatology/etr_2021.nc\n",
      "['potential_evapotranspiration']\n",
      "The file '/Users/meghana/gridmet_test_run/gridmet_climatology/etr_2021.csv' exists.\n",
      "reading values from /Users/meghana/gridmet_test_run/gridmet_climatology/etr_2020.nc\n",
      "['potential_evapotranspiration']\n",
      "The file '/Users/meghana/gridmet_test_run/gridmet_climatology/etr_2020.csv' exists.\n",
      "reading values from /Users/meghana/gridmet_test_run/gridmet_climatology/rmin_2020.nc\n",
      "['relative_humidity']\n",
      "The file '/Users/meghana/gridmet_test_run/gridmet_climatology/rmin_2020.csv' exists.\n",
      "reading values from /Users/meghana/gridmet_test_run/gridmet_climatology/tmmn_2020.nc\n",
      "['air_temperature']\n",
      "The file '/Users/meghana/gridmet_test_run/gridmet_climatology/tmmn_2020.csv' exists.\n",
      "reading values from /Users/meghana/gridmet_test_run/gridmet_climatology/tmmx_2021.nc\n",
      "['air_temperature']\n",
      "The file '/Users/meghana/gridmet_test_run/gridmet_climatology/tmmx_2021.csv' exists.\n",
      "reading values from /Users/meghana/gridmet_test_run/gridmet_climatology/tmmx_2020.nc\n",
      "['air_temperature']\n",
      "The file '/Users/meghana/gridmet_test_run/gridmet_climatology/tmmx_2020.csv' exists.\n",
      "reading values from /Users/meghana/gridmet_test_run/gridmet_climatology/vpd_2020.nc\n",
      "['mean_vapor_pressure_deficit']\n",
      "The file '/Users/meghana/gridmet_test_run/gridmet_climatology/vpd_2020.csv' exists.\n",
      "reading values from /Users/meghana/gridmet_test_run/gridmet_climatology/pr_2021.nc\n",
      "['precipitation_amount']\n",
      "The file '/Users/meghana/gridmet_test_run/gridmet_climatology/pr_2021.csv' exists.\n",
      "reading values from /Users/meghana/gridmet_test_run/gridmet_climatology/pr_2020.nc\n",
      "['precipitation_amount']\n",
      "The file '/Users/meghana/gridmet_test_run/gridmet_climatology/pr_2020.csv' exists.\n",
      "reading values from /Users/meghana/gridmet_test_run/gridmet_climatology/vpd_2021.nc\n",
      "['mean_vapor_pressure_deficit']\n",
      "The file '/Users/meghana/gridmet_test_run/gridmet_climatology/vpd_2021.csv' exists.\n",
      "reading values from /Users/meghana/gridmet_test_run/gridmet_climatology/vs_2021.nc\n",
      "['wind_speed']\n",
      "The file '/Users/meghana/gridmet_test_run/gridmet_climatology/vs_2021.csv' exists.\n",
      "reading values from /Users/meghana/gridmet_test_run/gridmet_climatology/rmax_2020.nc\n",
      "['relative_humidity']\n",
      "The file '/Users/meghana/gridmet_test_run/gridmet_climatology/rmax_2020.csv' exists.\n",
      "reading values from /Users/meghana/gridmet_test_run/gridmet_climatology/vs_2020.nc\n",
      "['wind_speed']\n",
      "The file '/Users/meghana/gridmet_test_run/gridmet_climatology/vs_2020.csv' exists.\n",
      "reading values from /Users/meghana/gridmet_test_run/gridmet_climatology/rmax_2021.nc\n",
      "['relative_humidity']\n",
      "The file '/Users/meghana/gridmet_test_run/gridmet_climatology/rmax_2021.csv' exists.\n",
      "Merged ['tmmn_2020.csv', 'tmmn_2021.csv', 'tmmn_merged.csv'] into tmmn_merged.csv\n",
      "Merged ['vs_merged.csv', 'vs_2020.csv', 'vs_2021.csv'] into vs_merged.csv\n",
      "Merged ['rmax_merged.csv', 'rmax_2020.csv', 'rmax_2021.csv'] into rmax_merged.csv\n",
      "Merged ['etr_merged.csv', 'etr_2020.csv', 'etr_2021.csv'] into etr_merged.csv\n",
      "Merged ['vpd_merged.csv', 'vpd_2020.csv', 'vpd_2021.csv'] into vpd_merged.csv\n",
      "Merged ['tmmx_2021.csv', 'tmmx_2020.csv', 'tmmx_merged.csv'] into tmmx_merged.csv\n",
      "Merged ['pr_2021.csv', 'pr_2020.csv', 'pr_merged.csv'] into pr_merged.csv\n",
      "Merged ['rmin_2021.csv', 'rmin_merged.csv', 'rmin_2020.csv'] into rmin_merged.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import urllib.request\n",
    "from datetime import date, datetime\n",
    "\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from pathlib import Path\n",
    "\n",
    "import warnings\n",
    "\n",
    "#Chaging the timeframe to 1 year, instead of 10, for demonstration\n",
    "\n",
    "train_start_date = \"2020-01-03\"\n",
    "train_end_date = \"2021-12-31\"\n",
    "homedir = os.path.expanduser('~')\n",
    "work_dir = f\"{homedir}/gridmet_test_run\"\n",
    "\n",
    "# Suppress FutureWarnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "start_date = datetime.strptime(train_start_date, \"%Y-%m-%d\")\n",
    "end_date = datetime.strptime(train_end_date, \"%Y-%m-%d\")\n",
    "\n",
    "year_list = [start_date.year + i for i in range(end_date.year - start_date.year + 1)]\n",
    "\n",
    "working_dir = work_dir\n",
    "stations = pd.read_csv(f\"{work_dir}/all_snotel_cdec_stations_active_in_westus.csv\")\n",
    "gridmet_save_location = f'{working_dir}/gridmet_climatology'\n",
    "final_merged_csv = f\"{work_dir}/training_all_active_snotel_station_list_elevation.csv_gridmet.csv\"\n",
    "\n",
    "\n",
    "def get_files_in_directory():\n",
    "    f = list()\n",
    "    for files in glob.glob(gridmet_save_location + \"/*.nc\"):\n",
    "        f.append(files)\n",
    "    return f\n",
    "\n",
    "\n",
    "def download_file(url, save_location):\n",
    "    try:\n",
    "        print(\"download_file\")\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            file_content = response.read()\n",
    "        file_name = os.path.basename(url)\n",
    "        save_path = os.path.join(save_location, file_name)\n",
    "        with open(save_path, 'wb') as file:\n",
    "            file.write(file_content)\n",
    "        print(f\"File downloaded successfully and saved as: {save_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while downloading the file: {str(e)}\")\n",
    "\n",
    "\n",
    "def download_gridmet_climatology():\n",
    "    folder_name = gridmet_save_location\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "\n",
    "    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n",
    "    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n",
    "\n",
    "    for var in variables_list:\n",
    "        for y in year_list:\n",
    "            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n",
    "            print(\"downloading\", download_link)\n",
    "            if not os.path.exists(os.path.join(folder_name, var + '_' + '%s' % y + '.nc')):\n",
    "                download_file(download_link, folder_name)\n",
    "\n",
    "\n",
    "def get_gridmet_variable(file_name):\n",
    "    print(f\"reading values from {file_name}\")\n",
    "    result_data = []\n",
    "    ds = xr.open_dataset(file_name)\n",
    "    var_to_extract = list(ds.keys())\n",
    "    print(var_to_extract)\n",
    "    var_name = var_to_extract[0]\n",
    "    \n",
    "    df = pd.DataFrame(columns=['day', 'lat', 'lon', var_name])\n",
    "    \n",
    "    csv_file = f'{gridmet_save_location}/{Path(file_name).stem}.csv'\n",
    "    if os.path.exists(csv_file):\n",
    "    \tprint(f\"The file '{csv_file}' exists.\")\n",
    "    \treturn\n",
    "\n",
    "    for idx, row in stations.iterrows():\n",
    "        lat = row['latitude']\n",
    "        lon = row['longitude']\n",
    "\t\t\n",
    "        subset_data = ds.sel(lat=lat, lon=lon, method='nearest')\n",
    "        subset_data['lat'] = lat\n",
    "        subset_data['lon'] = lon\n",
    "        converted_df = subset_data.to_dataframe()\n",
    "        converted_df = converted_df.reset_index(drop=False)\n",
    "        converted_df = converted_df.drop('crs', axis=1)\n",
    "        df = pd.concat([df, converted_df], ignore_index=True)\n",
    "        \n",
    "    result_df = df\n",
    "    print(\"got result_df : \", result_df.head())\n",
    "    result_df.to_csv(csv_file, index=False)\n",
    "    print(f'completed extracting data for {file_name}')\n",
    "\n",
    "\n",
    "def merge_similar_variables_from_different_years():\n",
    "    files = os.listdir(gridmet_save_location)\n",
    "    file_groups = {}\n",
    "\n",
    "    for filename in files:\n",
    "        base_name, year_ext = os.path.splitext(filename)\n",
    "        parts = base_name.split('_')\n",
    "        if len(parts) == 2 and year_ext == '.csv':\n",
    "            file_groups.setdefault(parts[0], []).append(filename)\n",
    "\n",
    "    for base_name, file_list in file_groups.items():\n",
    "        if len(file_list) > 1:\n",
    "            dfs = []\n",
    "            for filename in file_list:\n",
    "                df = pd.read_csv(os.path.join(gridmet_save_location, filename))\n",
    "                dfs.append(df)\n",
    "            merged_df = pd.concat(dfs, ignore_index=True)\n",
    "            merged_filename = f\"{base_name}_merged.csv\"\n",
    "            merged_df.to_csv(os.path.join(gridmet_save_location, merged_filename), index=False)\n",
    "            print(f\"Merged {file_list} into {merged_filename}\")\n",
    "\n",
    "\n",
    "def merge_all_variables_together():\n",
    "    merged_df = None\n",
    "    file_paths = []\n",
    "\n",
    "    for filename in os.listdir(gridmet_save_location):\n",
    "        if filename.endswith(\"_merged.csv\"):\n",
    "            file_paths.append(os.path.join(gridmet_save_location, filename))\n",
    "\t\n",
    "    rmin_merged_path = os.path.join(gridmet_save_location, 'rmin_merged.csv')\n",
    "    rmax_merged_path = os.path.join(gridmet_save_location, 'rmax_merged.csv')\n",
    "    tmmn_merged_path = os.path.join(gridmet_save_location, 'tmmn_merged.csv')\n",
    "    tmmx_merged_path = os.path.join(gridmet_save_location, 'tmmx_merged.csv')\n",
    "    \n",
    "    df_rmin = pd.read_csv(rmin_merged_path)\n",
    "    df_rmax = pd.read_csv(rmax_merged_path)\n",
    "    df_tmmn = pd.read_csv(tmmn_merged_path)\n",
    "    df_tmmx = pd.read_csv(tmmx_merged_path)\n",
    "    \n",
    "    df_rmin.rename(columns={'relative_humidity': 'relative_humidity_rmin'}, inplace=True)\n",
    "    df_rmax.rename(columns={'relative_humidity': 'relative_humidity_rmax'}, inplace=True)\n",
    "    df_tmmn.rename(columns={'air_temperature': 'air_temperature_tmmn'}, inplace=True)\n",
    "    df_tmmx.rename(columns={'air_temperature': 'air_temperature_tmmx'}, inplace=True)\n",
    "    \n",
    "    df_rmin.to_csv(os.path.join(gridmet_save_location, 'rmin_merged.csv'))\n",
    "    df_rmax.to_csv(os.path.join(gridmet_save_location, 'rmax_merged.csv'))\n",
    "    df_tmmn.to_csv(os.path.join(gridmet_save_location, 'tmmn_merged.csv'))\n",
    "    df_tmmx.to_csv(os.path.join(gridmet_save_location, 'tmmx_merged.csv'))\n",
    "    \n",
    "    if file_paths:\n",
    "        merged_df = pd.read_csv(file_paths[0])\n",
    "        for file_path in file_paths[1:]:\n",
    "            df = pd.read_csv(file_path)\n",
    "            merged_df = pd.concat([merged_df, df], axis=1)\n",
    "        merged_df = merged_df.loc[:, ~merged_df.columns.duplicated()]\n",
    "        merged_df.to_csv(final_merged_csv, index=False)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    download_gridmet_climatology()\n",
    "    \n",
    "    nc_files = get_files_in_directory()\n",
    "    for nc in nc_files:\n",
    "        get_gridmet_variable(nc)\n",
    "    \n",
    "    merge_similar_variables_from_different_years()\n",
    "    merge_all_variables_together()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fe4521",
   "metadata": {},
   "source": [
    "We acquire and consolidate GridMET climate data. Initially, we download GridMET climate data files for specified variables and years, ensuring comprehensive coverage. Subsequently, we extract data for each station from these files and organize it into CSV format, simplifying data handling. Additionally, we intelligently merge similar variables from different years, streamlining data aggregation. Ultimately, we combine all variables into a unified dataset, facilitating seamless analysis or modeling tasks. This automation enhances efficiency and accuracy in climate data processing, benefiting various research or environmental applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e2e7ee",
   "metadata": {},
   "source": [
    "# AMSR Dataset\n",
    "\n",
    "## Introduction\n",
    "### What is AMSR?\n",
    "AMSR, short for Advanced Microwave Scanning Radiometer is a satellite-based instrument designed to measure microwave emissions from the Earth's surface and atmosphere. The AMSR dataset encompasses satellite-derived microwave observations crucial for a myriad of applications including weather forecasting, climate monitoring, and environmental studies. These datasets provide valuable insights into geophysical parameters such as sea surface temperature, soil moisture, sea ice concentration, precipitation, and wind speed over oceans. By collecting data on these factors, AMSR helps scientists better understand how water moves and behaves across the planet. Its observations provide valuable insights into Earth's climate dynamics and hydrological processes, contributing to our overall understanding of the environment.\n",
    "\n",
    "### Quick Look at the Data Collections\n",
    "AMSR-E, or the Advanced Microwave Scanning Radiometer for the Earth Observing System, is like a high-tech detective tool that travels on NASA's Aqua satellite. It gathers information about water on Earth and other important details about our environment. AMSR-E data collections include AMSR/ADEOS-II and AMSR2, hosted by the National Snow and Ice Data Center Distributed Active Archive Center (NSIDC DAAC). These datasets provide a treasure trove of polar observations, facilitating research in climatology, oceanography, hydrology, and more.\n",
    "\n",
    "## Characteristics\n",
    "- **Spatial Resolution**: AMSR provides data at various spatial resolutions depending on the specific instrument version and product. Typically, it offers moderate to high spatial resolution microwave data.\n",
    "\n",
    "- **Temporal Resolution**: AMSR data is available at various temporal resolutions, ranging from daily to monthly, depending on the specific product and parameters.\n",
    "\n",
    "- **Variables**: AMSR measures various parameters such as soil moisture, sea surface temperature, precipitation, snow water equivalent, and sea ice concentration using microwave radiometry.\n",
    "\n",
    "- **Coverage**: AMSR provides global coverage, allowing for the monitoring of environmental parameters across different regions of the Earth.\n",
    "\n",
    "- **Quality**: Data from AMSR undergoes rigorous quality control processes to ensure accuracy and reliability, considering factors such as calibration and validation against ground-based measurements.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://developers.google.com/earth-engine/datasets/images/TRMM/TRMM_3B43V7_sample.png\" alt=\"Sample Image from TRMM_3B43V7 dataset\" width=\"400\">\n",
    "</p>\n",
    "<p align=\"center\">AMSR from TRMM 3B43V7 dataset</p>\n",
    "\n",
    "\n",
    "## Data Format\n",
    "\n",
    "The Advanced Microwave Scanning Radiometer (AMSR) data is commonly stored in HDF5 format, providing a hierarchical structure for organizing datasets such as brightness temperature, sea surface temperature, and soil moisture. Within the HDF5 file, data parameters are organized into groups, with subgroups representing different configurations or subsets of the data. Metadata and geolocation information are typically stored separately, offering additional details about the data.\n",
    "\n",
    "## AMSR Data Collections\n",
    "### AMSR/ADEOS-II\n",
    "AMS/ADEOS-II, operating on the Advanced Earth Observing Satellite-II (ADEOS-II) platform, was the initial version of the AMSR instrument, providing passive microwave measurements from early 2003 to October 24, 2003. Offering Level-1A and Level-2A products, it served as a crucial tool for studying changes in polar ice caps, global precipitation patterns, and oceanic circulation. This data has been instrumental in enhancing our understanding of Earth's climate dynamics and informing research across various scientific disciplines.\n",
    "\n",
    "### AMSR2\n",
    "AMSR2, launched in 2012 onboard the Global Change Observation Mission-Water (GCOM-W1) satellite, represents the next generation of AMSR instruments. It continues the legacy of AMSR-E, capturing observations with improved spatial resolution and enhanced capabilities. AMSR2 data has been instrumental in monitoring sea ice extent, ocean surface winds, and soil moisture dynamics at global scales.\n",
    "\n",
    "### Hosted by NSIDC DAAC\n",
    "The NSIDC DAAC serves as the primary repository for AMSR-related data, ensuring that these valuable datasets are freely accessible to the scientific community and the public. The center provides data discovery, access, and user support services, facilitating research in cryospheric and hydrological sciences, climate modeling, and environmental monitoring.\n",
    "\n",
    "## Applications\n",
    "1. **Weather Forecasting**: AMSR data aids in short-term weather forecasting by providing insights into atmospheric moisture content and precipitation patterns.\n",
    "\n",
    "2. **Climate Monitoring**: AMSR datasets contribute to long-term climate monitoring efforts by providing data on parameters like sea surface temperature and sea ice concentration.\n",
    "\n",
    "3. **Oceanography**: AMSR data enables the study of ocean surface properties such as sea surface temperature, wind speed, and ocean salinity, facilitating research in oceanography and marine science.\n",
    "\n",
    "4. **Hydrology**: AMSR-derived soil moisture data supports hydrological modeling, drought monitoring, and water resource management by providing information on soil moisture content and surface water availability.\n",
    "\n",
    "5. **Cryosphere Studies**: AMSR datasets are crucial for studying the cryosphere, including monitoring changes in snow cover extent, snow water equivalent, and sea ice concentration, contributing to our understanding of climate change impacts in polar regions.\n",
    "\n",
    "# AMSR Dataset Download\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "244bcd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "def generate_links(start_year, end_year):\n",
    "    '''\n",
    "    Generate a list of download links for AMSR daily snow data files.\n",
    "\n",
    "    Args:\n",
    "        start_year (int): The starting year.\n",
    "        end_year (int): The ending year (inclusive).\n",
    "\n",
    "    Returns:\n",
    "        list: A list of download links for AMSR daily snow data files.\n",
    "    '''\n",
    "    base_url = \"https://n5eil01u.ecs.nsidc.org/AMSA/AU_DySno.001/\"\n",
    "    date_format = \"%Y.%m.%d\"\n",
    "    delta = timedelta(days=1)\n",
    "\n",
    "    start_date = datetime(start_year, 1, 1)\n",
    "    end_date = datetime(end_year + 1, 1, 1)\n",
    "\n",
    "    links = []\n",
    "    current_date = start_date\n",
    "\n",
    "    while current_date < end_date:\n",
    "        date_str = current_date.strftime(date_format)\n",
    "        link = base_url + date_str + \"/AMSR_U2_L3_DailySnow_B02_\" + date_str + \".he5\"\n",
    "        links.append(link)\n",
    "        current_date += delta\n",
    "\n",
    "    return links\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_year = 2019\n",
    "    end_year = 2022\n",
    "\n",
    "    links = generate_links(start_year, end_year)\n",
    "    homedir = os.path.expanduser('~')\n",
    "    working_dir = f\"{homedir}/gridmet_test_run\"\n",
    "    with open(f\"{working_dir}/amsr/download_links.txt\", \"w\") as txt_file:\n",
    "      for l in links:\n",
    "        txt_file.write(\" \".join(l) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f1f6ac",
   "metadata": {},
   "source": [
    "## MODIS Dataset\n",
    "\n",
    "### What is MODIS?\n",
    "MODIS, which stands for MODerate Resolution Imaging Spectroradiometer, is an advanced instrument operating aboard both the Terra and Aqua spacecraft. It captures a comprehensive view of Earth's surface, oceans, and atmosphere. The MODIS dataset is a comprehensive collection of Earth observation data captured by the MODIS instruments. Scientists use MODIS data to track changes in things like land cover, weather patterns, ice and snow, and the color of the oceans. MODIS boasts a remarkable viewing swath width of 2,330 km and covers the entire Earth surface every one to two days. With 36 spectral bands ranging from 0.405 to 14.385 µm, it provides detailed data at three spatial resolutions: 250m, 500m, and 1,000m.\n",
    "\n",
    "### Characteristics\n",
    "\n",
    "<blockquote>\n",
    "\n",
    "**Earth Science Data Type (ESDT)**: MOD10A1\n",
    "\n",
    "**Product Level**: L3\n",
    "\n",
    "**Nominal Data Array Dimensions**: 1200km by 1200km\n",
    "\n",
    "**Spatial Resolution**: 500m\n",
    "\n",
    "**Temporal Resolution**: day\n",
    "\n",
    "**Map Projection**: Sinusoidal \n",
    "\n",
    "</blockquote>\n",
    "\n",
    "### Data Format\n",
    "MODIS data are typically available in Hierarchical Data Format (HDF) or NetCDF formats, which are widely used for storing and distributing Earth observation data. These formats facilitate efficient data access, manipulation, and analysis using various software tools and programming languages commonly employed in the Earth sciences community.\n",
    "\n",
    "### MODIS Direct Broadcast\n",
    "Users with x-band receiving systems can capture regional data directly from the spacecraft using the MODIS Direct Broadcast signal, enhancing real-time monitoring capabilities.\n",
    "\n",
    "### fSCA\n",
    "\n",
    "Fractional Snow Covered Area (fSCA) is a metric used in the field of snow science and environmental studies to quantify the proportion of a given area that is covered by snow. It is derived from remote sensing data, particularly from sensors like Landsat, which capture images of the Earth's surface in various spectral bands. By analyzing these images, researchers can differentiate between snow-covered and snow-free areas, allowing them to calculate the percentage of the landscape covered by snow at a particular point in time. fSCA is valuable for understanding snow distribution patterns, monitoring changes in snow cover over time, and aiding in snowmelt and water resource management. It plays a crucial role in snowpack modeling, avalanche forecasting, and climate change research, providing essential data for informing decision-making processes related to snow-dependent ecosystems and human activities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ddb8f3",
   "metadata": {},
   "source": [
    "## SNOTEL dataset\n",
    "\n",
    "### What is SNOTEL?\n",
    "The SNOwpackTELemetryNetwork (SNOTEL) is an automated system of snowpack and climate sensors managed by the Natural Resources Conservation Service (NRCS) in the Western United States, offering critical data for water supply forecasting, flood prediction, and climate research. SNOTEL provides real-time data on snow water equivalent, snow depth, precipitation, and temperature from remote mountainous regions, aiding in understanding hydroclimatic conditions. SNOTEL offers comprehensive snowpack and climate data from over 900 sites, helping monitor snowpack, precipitation, temperature, and other climatic conditions in the western U.S.The SNOTEL dataset serves as a valuable resource for a wide range of stakeholders, contributing to informed decision-making in various sectors impacted by snowpack and climate conditions.\n",
    "\n",
    "### SNOTEL Network Overview\n",
    "#### Composition of SNOTEL\n",
    "- Comprising over 900 automated sites in remote, high-elevation mountain watersheds.\n",
    "- Monitors snowpack, precipitation, temperature, and other climatic parameters.\n",
    "\n",
    "#### Operations and Data Collection\n",
    "- Sites operate unattended and without maintenance for extended periods.\n",
    "- Standard sensor configuration includes snow pillow, precipitation gauge, and temperature sensors.\n",
    "\n",
    "### Telemetry and Data Transmission\n",
    "#### Data Collection and Storage\n",
    "- Dataloggers installed in equipment shelters collect and store data.\n",
    "- Various telemetry systems transmit data back to the Water and Climate Information System.\n",
    "\n",
    "### Enhanced Site Capabilities\n",
    "- Enhanced sites equipped with soil moisture, soil temperature, solar radiation, wind speed, and relative humidity sensors.\n",
    "- Tailored configurations based on physical conditions and climate requirements.\n",
    "\n",
    "### Characteristics\n",
    "<blockquote>\n",
    "\n",
    "**Product/Data Type**: SNOTEL Station Daily Data\n",
    "\n",
    "**Spatial Resolution**: Point data specific to each SNOTEL station location present in the western USA within bounding box of\n",
    "southwest_lon = -125.0\n",
    "southwest_lat = 25.0\n",
    "northeast_lon = -100.0\n",
    "northeast_lat = 49.0\n",
    "\n",
    "**Temporal Resolution**: Daily\n",
    "\n",
    "**Quality**: SNOTEL data undergoes quality control procedures to ensure accuracy and reliability, including calibration checks and validation against manual measurements.\n",
    "\n",
    "</blockquote>\n",
    "\n",
    "\n",
    "### Data Format\n",
    "The Snow Telemetry (SNOTEL) data format encompasses structured datasets collected from remote automated stations situated in mountainous regions, monitoring snowpack, weather, and hydrological parameters. Key aspects include recorded parameters such as snow water equivalent (SWE), snow depth, air temperature, and precipitation, timestamped to denote observation times and often stored at varying resolutions like hourly or daily intervals. Quality control flags accompany data points to denote reliability, while metadata provides station details and sensor calibration information. SNOTEL data is commonly stored in formats like CSV, TSV, HDF5, or netCDF, accessible through agency websites, data portals, or APIs. This format facilitates applications spanning water resource management, climate research, agriculture, recreation, hydrological modeling, and ecological studies.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://www.climate.gov/sites/default/files/2021-08/DatasetGallery_Snow-Water-Equivalent-in-Western-Basins-Interactive-Graph_thumb_16x9.png\" alt=\"Snow Water Equivalent in Western Basins\" width=\"600\">\n",
    "</p>\n",
    "<p align=\"center\">Snow Water Equivalent in Western Basins</p>\n",
    "<br>\n",
    "\n",
    "<img src=\"../img/SNOTEL.jpeg\" alt=\"Snow Water Equivalent Percent NRCS 1991-2020 Median April 6 2024\" width=\"600\" align=\"center\">\n",
    "\n",
    "<p align=\"center\">Snow Water Equivalent Percent NRCS 1991-2020 Median April 6 2024</p>\n",
    "\n",
    "\n",
    "**For map visualization of SNOWTEL stations, click on ‘SNOWTEL data’ under ‘Climate Monitoring’ in the right panel. The maps are clickable for station selection.**\n",
    "\n",
    "For more information, visit the [NRCS SNOTEL page](https://www.nrcs.usda.gov/wps/portal/wcc/home/aboutUs/monitoringPrograms/automatedSnowMonitoring).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afc5f94",
   "metadata": {},
   "source": [
    "## DEM Dataset\n",
    "\n",
    "A Digital Elevation Model (DEM) is a digital representation of the topography of a surface, such as the Earth's terrain or the surface of another celestial body. It consists of a grid of elevation values, where each cell in the grid represents the elevation at a specific location. DEMs are widely used in various fields, including geography, geology, hydrology, environmental modeling, urban planning, and 3D visualization.\n",
    "\n",
    "### Characteristics\n",
    "\n",
    "<blockquote>\n",
    "\n",
    "**Product/Data Type**: SRTM 90m Digital Elevation Model (DEM)\n",
    "\n",
    "**Nominal Data Array Dimensions**: 5° x 5° tiles\n",
    "\n",
    "**Spatial Resolution**: 90 meters (at the equator)\n",
    "\n",
    "**Temporal Resolution**: Single-time snapshot (data captured during the SRTM mission in 2000)\n",
    "\n",
    "**Vertical Accuracy**: Less than 16 meters error\n",
    "\n",
    "**Data Format**: ArcInfo ASCII and GeoTiff\n",
    "\n",
    "**Coverage**: Western USA\n",
    "\n",
    "**Projection**: WGS84 datum, geographic coordinate system\n",
    "\n",
    "</blockquote>\n",
    "\n",
    "DEM data is typically stored in raster formats such as GeoTIFF, ASCII grid, or Esri GRID. DEM data is typically stored in raster formats such as GeoTIFF, ASCII grid, or Esri GRID. Additional information such as coordinate system, spatial resolution, and metadata may also be included in the data file.\n",
    "\n",
    "\n",
    "<img src=\"../img/DEM/elevation_map.png\" alt=\"Elevation Map\" height=\"300\" width=\"300\"/>\n",
    "<img src=\"../img/DEM/aspect_map.png\" alt=\"Aspect Map\" height=\"300\" width=\"300\">\n",
    "\n",
    "<img src=\"../img/DEM/northness_map.png\" alt=\"Nothness Map\" height=\"300\" width=\"300\">\n",
    "<img src=\"../img/DEM/eastness_map.png\" alt=\"Eastness Map\" height=\"300\" width=\"300\">\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
