{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5910c4dd",
   "metadata": {},
   "source": [
    "# Analyzing Snowpack Data with Python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2657d52e",
   "metadata": {},
   "source": [
    "## Chapter 1 : Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ac46bf",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "This chapter introduces the significance of analyzing snowpack data, focusing on the Snow Telemetry (SNOTEL) and California Data Exchange Center (CDEC) stations. These stations play a crucial role in monitoring snowpack dynamics across the Western United States, providing vital data for water resource management, climatological research, and environmental conservation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df3df2e",
   "metadata": {},
   "source": [
    "### 1.2. Objectives\n",
    "\n",
    "- Understand the importance of snowpack data.\n",
    "- Learn how to automate the retrieval, processing, and analysis of snowpack data using Python.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78629a1b",
   "metadata": {},
   "source": [
    "## Chapter 2: Setting Up Your Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802b3575",
   "metadata": {},
   "source": [
    "## 2.1.1. Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e2823c",
   "metadata": {},
   "source": [
    "### 2.1. Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42b0781",
   "metadata": {},
   "source": [
    "**. Python 3.x**\n",
    "\n",
    "\n",
    "**. Libraries: math, json, requests, pandas, csv, io, os, dask**\n",
    "\n",
    "\n",
    "**. A working directory for storing downloaded files**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c55c8a0",
   "metadata": {},
   "source": [
    "### 2.2. Environment Preparation\n",
    "\n",
    "Instructions on setting up the Python environment, installing necessary libraries using pip, and organizing your workspace for efficient data handling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c9b475",
   "metadata": {},
   "source": [
    "### 2.3.1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea9c7c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 0: Import Libraries\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0af64d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "WORK_DIR = 'C:\\\\Users\\\\Lenovo\\\\Documents\\\\SNOTEL Training'\n",
    "STATION_JSON_URL = \"https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\"\n",
    "OUTPUT_JSON_FILE = f'{WORK_DIR}/all_snotel_cdec_stations.json'\n",
    "OUTPUT_CSV_FILE = f'{WORK_DIR}/all_snotel_cdec_stations.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dfe634",
   "metadata": {},
   "source": [
    "## Chapter 3: Fetching Station Data\n",
    "\n",
    "### 3.1. Understanding APIs\n",
    "\n",
    "A brief introduction to APIs (Application Programming Interfaces), focusing on how the SNOTEL and CDEC API provides access to station data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f21d5f",
   "metadata": {},
   "source": [
    "### 3.2. Writing the Download Function\n",
    "\n",
    "Explains the `download_station_json` function, which uses the `requests` library to fetch JSON data from the SNOTEL and CDEC API. This section includes handling HTTP responses to ensure successful data retrieval.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dba328b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Download Station Data\n",
    "def download_station_json():\n",
    "    response = requests.get(STATION_JSON_URL)\n",
    "    if response.status_code == 200:\n",
    "        with open(OUTPUT_JSON_FILE, 'w') as json_file:\n",
    "            json.dump(response.json(), json_file, indent=2)\n",
    "        print(\"Data downloaded and saved.\")\n",
    "    else:\n",
    "        print(\"Failed to download data. Status code:\", response.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b314254d",
   "metadata": {},
   "source": [
    "## Chapter 4: Transforming Data Formats\n",
    "\n",
    "### 4.1. From JSON to CSV\n",
    "\n",
    "Discusses the rationale behind converting JSON data to CSV format for easier manipulation and analysis. It includes a step-by-step guide on using the `pandas` library for the conversion process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b01d219",
   "metadata": {},
   "source": [
    "### 4.2. Implementing the Conversion\n",
    "\n",
    "Detailed explanation of the `convert_json_to_csv` function, illustrating how to read JSON from a file, normalize nested JSON into a flat table, and save the result as a CSV file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31dfdaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Convert JSON to CSV\n",
    "def convert_json_to_csv():\n",
    "    with open(OUTPUT_JSON_FILE, 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "    df = pd.json_normalize(data)\n",
    "    df.to_csv(OUTPUT_CSV_FILE, index=False)\n",
    "    print(\"JSON converted to CSV.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa3622c",
   "metadata": {},
   "source": [
    "## Chapter 5: Filtering Relevant Stations\n",
    "\n",
    "### 5.1. The Need for Filtering\n",
    "\n",
    "Outlines why filtering stations based on specific criteria (e.g., geographic coordinates) is necessary for targeted analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cdfa72",
   "metadata": {},
   "source": [
    "### 5.2. Crafting the Filter\n",
    "\n",
    "Provides an in-depth look at the `filter_stations` function, demonstrating how to use `pandas` to apply filters to the CSV data. This section explains selecting rows based on conditions, such as latitude greater than 40 degrees.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbaf6a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Filter Stations (Example filtering logic; adjust as needed)\n",
    "def filter_stations():\n",
    "    df = pd.read_csv(OUTPUT_CSV_FILE)\n",
    "    # Example filter: Latitude > 40\n",
    "    filtered_df = df[df['latitude'] > 40]\n",
    "    print(filtered_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578101f0",
   "metadata": {},
   "source": [
    "## Chapter 6: Conclusion and Next Steps\n",
    "\n",
    "### 6.1. Review\n",
    "\n",
    "Summarizes the script's functionality and the theoretical knowledge provided in the previous chapters, reinforcing the importance of each step in the data analysis process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87f2bc86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data downloaded and saved.\n",
      "JSON converted to CSV.\n",
      "    stationTriplet stationId stateCode networkCode                    name  \\\n",
      "2     0010:ID:COOP      0010        ID        COOP  Aberdeen Experimnt Stn   \n",
      "3    1F01A:BC:SNOW     1F01A        BC        SNOW           Aberdeen Lake   \n",
      "6    13E19:ID:SNOW     13E19        ID        SNOW           Above Gilmore   \n",
      "7    15B07:ID:SNOW     15B07        ID        SNOW            Above Roland   \n",
      "9  06110500:MT:BOR  06110500        MT         BOR             Ackley Lake   \n",
      "\n",
      "  dcoCode    countyName           huc  elevation  latitude  longitude  \\\n",
      "2      ID       Bingham  1.704021e+11     4410.0  42.95000 -112.83333   \n",
      "3      OR       UNKNOWN           NaN     4298.0  50.14733 -119.05340   \n",
      "6      ID         Lemhi  1.706020e+11     8289.0  44.45615 -113.30097   \n",
      "7      ID      Shoshone  1.701030e+11     4347.0  47.38507 -115.66405   \n",
      "9      MT  Judith Basin  1.004010e+11     4300.0  46.95741 -109.94062   \n",
      "\n",
      "   dataTimeZone pedonCode shefId              beginDate                endDate  \n",
      "2           NaN       NaN  ABDI1  1914-01-01 00:00:00.0  2100-01-01 00:00:00.0  \n",
      "3           NaN       NaN  ABLQ2  1939-04-01 00:00:00.0  2100-01-01 00:00:00.0  \n",
      "6           NaN       NaN  ABGI1  1961-01-01 00:00:00.0  2100-01-01 00:00:00.0  \n",
      "7           NaN       NaN  ABRI1  1926-03-01 00:00:00.0  2100-01-01 00:00:00.0  \n",
      "9           NaN       NaN    NaN  1938-06-01 00:00:00.0  2100-01-01 00:00:00.0  \n"
     ]
    }
   ],
   "source": [
    "# Step 4: Main function to execute the steps\n",
    "def main():\n",
    "    download_station_json()\n",
    "    convert_json_to_csv()\n",
    "    filter_stations()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c489691",
   "metadata": {},
   "source": [
    "This code snippet is a basic Python script that outlines a process for handling and transforming weather station data. It consists of a main function, `main()`, that orchestrates three key steps in the data handling process: downloading JSON data, converting that JSON data into a CSV format, and finally filtering the stations based on certain criteria. The script is designed to be executed as a standalone program, as indicated by the `if __name__ == \"__main__\":` condition, which ensures that the `main()` function is called only when the script is run directly, and not when imported as a module.\n",
    "\n",
    "The snippet also includes an example output that showcases the result of the operations, particularly the conversion of JSON to CSV format. This output displays a table with selected columns such as `stationTriplet`, `stationId`, `stateCode`, `networkCode`, `name`, `dcoCode`, `countyName`, `huc`, `elevation`, `latitude`, `longitude`, `dataTimeZone`, `pedonCode`, `shefId`, `beginDate`, and `endDate`. These columns represent various attributes of weather stations, including their IDs, names, geographic locations (state, county, latitude, longitude), elevation, and the time range for which data is available.\n",
    "\n",
    "The script presumably performs the following operations:\n",
    "1. **Downloading JSON Data**: It fetches weather station data in JSON format from a remote source or local storage.\n",
    "2. **Converting JSON to CSV**: The JSON data is then converted into a more universally readable comma-separated values (CSV) format, facilitating easier data manipulation and analysis.\n",
    "3. **Filtering Stations**: Lastly, the script filters the stations based on predefined criteria, which could include factors like geographic location, data availability period, or specific attributes of the stations. \n",
    "\n",
    "This process is essential for data preparation, especially in meteorological or geographical information system (GIS) applications, where handling large datasets and converting them into a more accessible format is a preliminary step for further analysis or visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b347c3",
   "metadata": {},
   "source": [
    "This structured approach aims to equip readers with both the theoretical background and practical skills needed to harness Python for snowpack data analysis, promoting a deeper understanding of environmental data's role in research and decision-making."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
