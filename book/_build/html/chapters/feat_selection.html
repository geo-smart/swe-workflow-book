
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Feature Selection for SWE Prediction Models &#8212; Snow Water Equivalent Workflow</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="../_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=36754332"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chapters/feat_selection';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Cumulative Time Series Analysis" href="time_series.html" />
    <link rel="prev" title="AMSR" href="amsr.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="Snow Water Equivalent Workflow - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="Snow Water Equivalent Workflow - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Chapter One</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="motivation.html">Motivation</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Chapter Two</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="overview.html">Overview of the SWE Workflow</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Chapter Three</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="datasource.html">Training and Testing Dataset Overview</a></li>











<li class="toctree-l1"><a class="reference internal" href="gridmet.html">GridMET Climatology Data Downloader</a></li>


<li class="toctree-l1"><a class="reference internal" href="snotel.html">SNOTEL</a></li>
<li class="toctree-l1"><a class="reference internal" href="fsCA.html">MODIS for fsCA</a></li>
<li class="toctree-l1"><a class="reference internal" href="dem.html">Digital Elevation Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="amsr.html">AMSR</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Chapter Four</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Feature Selection</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Chapter Five</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="time_series.html">Cumulative Time series analysis</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Chapter Six</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="sanity_checks.html">Workflow Sanity Checks</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Chapter Seven</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="model_training.html">Model Training</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Chapter Eight</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="validation.html">Model Testing &amp; Validation</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Chapter Nine</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="predictions.html">Model Predictions / Results</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Chapter Ten</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="conclusion.html">Conclusion</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Reference</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../reference/glossary.html">Glossaries</a></li>
<li class="toctree-l1"><a class="reference internal" href="../reference/bibliography.html">Bibliography</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://mybinder.org/v2/gh/geo-smart/use_case_template/main?urlpath=lab/tree/book/chapters/feat_selection.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onBinder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/geo-smart/use_case_template" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/geo-smart/use_case_template/edit/main/book/chapters/feat_selection.ipynb" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/geo-smart/use_case_template/issues/new?title=Issue%20on%20page%20%2Fchapters/feat_selection.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/chapters/feat_selection.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Feature Selection for SWE Prediction Models</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-to-the-data">Introduction to the Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-1-integrating-the-datasets-with-dask">Step 1: Integrating the Datasets with Dask</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#read-and-convert">Read and Convert</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#merge-on-common-ground">Merge on Common Ground</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#output">Output</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-2-preprocessing-for-feature-selection">Step 2: Preprocessing for Feature Selection</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-3-advanced-merging-and-cleaning">Step 3: Advanced Merging and Cleaning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion-the-ready-to-train-dataset">Conclusion: The Ready-to-Train Dataset</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="feature-selection-for-swe-prediction-models">
<h1>Feature Selection for SWE Prediction Models<a class="headerlink" href="#feature-selection-for-swe-prediction-models" title="Link to this heading">#</a></h1>
<p>Criteria for selecting features in SWE prediction models, Techniques and tools used for feature selection</p>
<section id="introduction-to-the-data">
<h2>Introduction to the Data<a class="headerlink" href="#introduction-to-the-data" title="Link to this heading">#</a></h2>
<p>The three key datasets:</p>
<ul class="simple">
<li><p><strong>Climatology Data:</strong> Offers a broad view of weather patterns over time.</p></li>
<li><p><strong>SNOTEL Data:</strong> Provides specific insights into snowpack conditions.</p></li>
<li><p><strong>Terrain Data:</strong> Brings in the geographical and physical characteristics of the landscape.</p></li>
</ul>
<p>Each dataset comes packed with essential features like latitude, longitude, and date, ready to enrich our SWE prediction model.</p>
</section>
<section id="step-1-integrating-the-datasets-with-dask">
<h2>Step 1: Integrating the Datasets with Dask<a class="headerlink" href="#step-1-integrating-the-datasets-with-dask" title="Link to this heading">#</a></h2>
<p>We are combining these large datasets into one DataFrame using Dask. Dask allows us to work with big data efficiently, so we can merge the datasets quickly and easily, no matter how large they are.</p>
<p>And also if the size of the data is larger then reading large CSV files in chunks helps manage big data more efficiently by reducing memory use, speeding up processing, and improving error handling. This approach makes it easier to work on large datasets with limited resources, ensuring flexibility and scalability in data analysis.</p>
<section id="read-and-convert">
<h3>Read and Convert<a class="headerlink" href="#read-and-convert" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Each CSV file is read into a Dask DataFrame, with latitude and longitude data types converted to floats for uniformity. And also if the size of the data is larger then reading large CSV files in chunks helps manage big data more efficiently by reducing memory use, speeding up processing, and improving error handling. This approach makes it easier to work on large datasets with limited resources, ensuring flexibility and scalability in data analysis.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">dask.dataframe</span> <span class="k">as</span> <span class="nn">dd</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="n">file_path1</span> <span class="o">=</span> <span class="s1">&#39;../data/training_ready_climatology_data.csv&#39;</span>
<span class="n">file_path2</span> <span class="o">=</span> <span class="s1">&#39;../data/training_ready_snotel_data.csv&#39;</span>
<span class="n">file_path3</span> <span class="o">=</span> <span class="s1">&#39;../data/training_ready_terrain_data.csv&#39;</span>
<span class="c1"># Read each CSV file into a Dask DataFrame</span>
<span class="n">df1</span> <span class="o">=</span> <span class="n">dd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">file_path1</span><span class="p">)</span>
<span class="n">df2</span> <span class="o">=</span> <span class="n">dd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">file_path2</span><span class="p">)</span>
<span class="n">df3</span> <span class="o">=</span> <span class="n">dd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">file_path3</span><span class="p">)</span>
<span class="c1"># Perform data type conversion for latitude and longitude columns</span>
<span class="n">df1</span><span class="p">[</span><span class="s1">&#39;lat&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df1</span><span class="p">[</span><span class="s1">&#39;lat&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
<span class="n">df1</span><span class="p">[</span><span class="s1">&#39;lon&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df1</span><span class="p">[</span><span class="s1">&#39;lon&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
<span class="n">df2</span><span class="p">[</span><span class="s1">&#39;lat&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df2</span><span class="p">[</span><span class="s1">&#39;lat&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
<span class="n">df2</span><span class="p">[</span><span class="s1">&#39;lon&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df2</span><span class="p">[</span><span class="s1">&#39;lon&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
<span class="n">df3</span><span class="p">[</span><span class="s1">&#39;lat&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df3</span><span class="p">[</span><span class="s1">&#39;lat&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
<span class="n">df3</span><span class="p">[</span><span class="s1">&#39;lon&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df3</span><span class="p">[</span><span class="s1">&#39;lon&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
<span class="c1">#rename the columns to match the other dataframes</span>
<span class="n">df2</span> <span class="o">=</span> <span class="n">df2</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;Date&quot;</span><span class="p">:</span> <span class="s2">&quot;date&quot;</span><span class="p">})</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="merge-on-common-ground">
<h3>Merge on Common Ground<a class="headerlink" href="#merge-on-common-ground" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>The dataframes are then merged based on shared columns (latitude, longitude, and date), ensuring that each row represents a coherent set of data from all three sources.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Merge the first two DataFrames based on &#39;lat&#39;, &#39;lon&#39;, and &#39;date&#39;</span>
<span class="n">merged_df1</span> <span class="o">=</span> <span class="n">dd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">df1</span><span class="p">,</span> <span class="n">df2</span><span class="p">,</span> <span class="n">left_on</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;lat&#39;</span><span class="p">,</span> <span class="s1">&#39;lon&#39;</span><span class="p">,</span> <span class="s1">&#39;date&#39;</span><span class="p">],</span> <span class="n">right_on</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;lat&#39;</span><span class="p">,</span> <span class="s1">&#39;lon&#39;</span><span class="p">,</span> <span class="s1">&#39;date&#39;</span><span class="p">])</span>

<span class="c1"># Merge the third DataFrame based on &#39;lat&#39; and &#39;lon&#39;</span>
<span class="n">merged_df2</span> <span class="o">=</span> <span class="n">dd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">merged_df1</span><span class="p">,</span> <span class="n">df3</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;lat&#39;</span><span class="p">,</span> <span class="s1">&#39;lon&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="output">
<h3>Output<a class="headerlink" href="#output" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>The merged DataFrame is saved as a new CSV file, ready for further processing or analysis.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">merged_df2</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;../data/model_training_data.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">single_file</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;/Users/vangavetisaivivek/research/swe-workflow-book/book/data/model_training_data.csv&#39;]
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="step-2-preprocessing-for-feature-selection">
<h2>Step 2: Preprocessing for Feature Selection<a class="headerlink" href="#step-2-preprocessing-for-feature-selection" title="Link to this heading">#</a></h2>
<p>Preprocessing steps are crucial for fine-tuning the data to ensure it’s model-ready. This includes:</p>
<ul class="simple">
<li><p><strong>Date-Range Data Clipping:</strong> This step focuses on trimming the data to fit a specified date range, which is necessary for the analysis. After this trimming process, we save the refined data back into a CSV file.</p></li>
<li><p><strong>Filtering:</strong> Select only the relevant columns needed for SWE prediction, such as weather conditions, geographic features, and snowpack measurements.</p></li>
<li><p><strong>Renaming:</strong> Streamline column names for consistency and clarity (e.g., changing “Snow Water Equivalent (in) Start of Day Values” to “swe_value”).</p></li>
</ul>
<p>save the final data into csv file.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">input_csv</span> <span class="o">=</span> <span class="s1">&#39;../data/model_training_data.csv&#39;</span>

<span class="c1"># List of columns you want to extract</span>
<span class="n">selected_columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">,</span> <span class="s1">&#39;lat&#39;</span><span class="p">,</span> <span class="s1">&#39;lon&#39;</span><span class="p">,</span> <span class="s1">&#39;etr&#39;</span><span class="p">,</span> <span class="s1">&#39;pr&#39;</span><span class="p">,</span> <span class="s1">&#39;rmax&#39;</span><span class="p">,</span>
                    <span class="s1">&#39;rmin&#39;</span><span class="p">,</span> <span class="s1">&#39;tmmn&#39;</span><span class="p">,</span> <span class="s1">&#39;tmmx&#39;</span><span class="p">,</span> <span class="s1">&#39;vpd&#39;</span><span class="p">,</span> <span class="s1">&#39;vs&#39;</span><span class="p">,</span> 
                    <span class="s1">&#39;elevation&#39;</span><span class="p">,</span>
                    <span class="s1">&#39;slope&#39;</span><span class="p">,</span> <span class="s1">&#39;curvature&#39;</span><span class="p">,</span> <span class="s1">&#39;aspect&#39;</span><span class="p">,</span> <span class="s1">&#39;eastness&#39;</span><span class="p">,</span>
                    <span class="s1">&#39;northness&#39;</span><span class="p">,</span> <span class="s1">&#39;Snow Water Equivalent (in) Start of Day Values&#39;</span><span class="p">]</span>
<span class="c1"># Read the CSV file into a Dask DataFrame</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">dd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">input_csv</span><span class="p">,</span> <span class="n">usecols</span><span class="o">=</span><span class="n">selected_columns</span><span class="p">)</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;Snow Water Equivalent (in) Start of Day Values&quot;</span><span class="p">:</span> <span class="s2">&quot;swe_value&quot;</span><span class="p">})</span>

<span class="c1"># Replace &#39;output.csv&#39; with the desired output file name</span>
<span class="n">output_csv</span> <span class="o">=</span> <span class="s1">&#39;../data/model_training_cleaned.csv&#39;</span>

<span class="c1"># Write the selected columns to a new CSV file</span>
<span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">output_csv</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">single_file</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;/Users/vangavetisaivivek/research/swe-workflow-book/book/data/model_training_cleaned.csv&#39;]
</pre></div>
</div>
</div>
</div>
</section>
<section id="step-3-advanced-merging-and-cleaning">
<h2>Step 3: Advanced Merging and Cleaning<a class="headerlink" href="#step-3-advanced-merging-and-cleaning" title="Link to this heading">#</a></h2>
<p>For a deeper dive, additional scripts provide a more intricate merging process involving multiple data sources and filters based on time ranges. The aim here is to:</p>
<ul class="simple">
<li><p><strong>Integrate Further Data:</strong> Additional sources like AMSR data are introduced, expanding the dataset with more variables relevant to SWE prediction.</p></li>
<li><p><strong>Optimize and Clean:</strong> Repartitioning and dropping duplicates are applied post-merge to ensure the dataset is optimized for processing and free of redundancy.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">dask.dataframe</span> <span class="k">as</span> <span class="nn">dd</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">homedir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="s1">&#39;~&#39;</span><span class="p">)</span>
<span class="n">working_dir</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;../data&quot;</span>
<span class="n">work_dir</span> <span class="o">=</span> <span class="n">working_dir</span>
<span class="n">final_output_name</span> <span class="o">=</span> <span class="s2">&quot;final_merged_data_3yrs_all_active_stations_v1.csv&quot;</span>
<span class="n">chunk_size</span> <span class="o">=</span> <span class="s1">&#39;10MB&#39;</span>  <span class="c1"># You can adjust this chunk size based on your hardware and data size</span>
</pre></div>
</div>
</div>
</div>
<p>It begins by importing necessary libraries like dask.dataframe, os, pandas.</p>
<ul class="simple">
<li><p><strong>dask.dataframe:</strong> This is for handling large datasets efficiently. Dask is a Python library that allows for parallel computing and works well with datasets too large for the memory of a single computer.</p></li>
<li><p><strong>os:</strong> This module provides a way of using operating system-dependent functionality like reading or writing to a file system.</p></li>
<li><p><strong>pandas</strong>: This module is great for data manipulation and analysis. It’s particularly used for working with tabular data (like spreadsheets and SQL database outputs).</p></li>
</ul>
<p>Initially, it identifies the user’s home directory to establish a base location. Subsequently, within this base location, we are giving a specific path which is directory named ‘data’ where we have provided all the data that is needed for analysis. Then we define the name of the output file,
final_merged_data_3yrs_all_active_stations_v1.csv. To efficiently manage computer memory during this operation, the data will be processed in segments, each limited to 10MB.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">amsr_file</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">working_dir</span><span class="si">}</span><span class="s1">/all_snotel_cdec_stations_active_in_westus.csv_amsr_dask.csv&#39;</span>
<span class="n">snotel_file</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">working_dir</span><span class="si">}</span><span class="s1">/all_snotel_cdec_stations_active_in_westus.csv_swe_restored_dask_all_vars.csv&#39;</span>
<span class="n">gridmet_file</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">working_dir</span><span class="si">}</span><span class="s1">/training_all_active_snotel_station_list_elevation.csv_gridmet.csv&#39;</span>
<span class="n">terrain_file</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">working_dir</span><span class="si">}</span><span class="s1">/training_all_active_snotel_station_list_elevation.csv_terrain_4km_grid_shift.csv&#39;</span>
<span class="n">fsca_file</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">working_dir</span><span class="si">}</span><span class="s1">/fsca_final_training_all.csv&#39;</span>
<span class="n">final_final_output_file</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">work_dir</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="n">final_output_name</span><span class="si">}</span><span class="s1">&#39;</span>

<span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">final_final_output_file</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The file &#39;</span><span class="si">{</span><span class="n">final_final_output_file</span><span class="si">}</span><span class="s2">&#39; exists. Skipping&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Here we are defining the input and output files, checks if the final output file already exists. If it does, it prints a message and skips further processing.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Read the CSV files with a smaller chunk size and compression</span>
<span class="n">amsr</span> <span class="o">=</span> <span class="n">dd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">amsr_file</span><span class="p">,</span> <span class="n">blocksize</span><span class="o">=</span><span class="n">chunk_size</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;amsr.columns = &quot;</span><span class="p">,</span> <span class="n">amsr</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>amsr.columns =  Index([&#39;date&#39;, &#39;lat&#39;, &#39;lon&#39;, &#39;AMSR_SWE&#39;], dtype=&#39;object&#39;)
</pre></div>
</div>
</div>
</div>
<p>It reads data from CSV file into Dask DataFrames by blocks which provides a flexible and efficient approach for handling large datasets, enabling better scalability and performance in data processing tasks.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">snotel</span> <span class="o">=</span> <span class="n">dd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">snotel_file</span><span class="p">,</span> <span class="n">blocksize</span><span class="o">=</span><span class="n">chunk_size</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;snotel.columns = &quot;</span><span class="p">,</span> <span class="n">snotel</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>snotel.columns =  Index([&#39;station_name&#39;, &#39;date&#39;, &#39;lat&#39;, &#39;lon&#39;, &#39;swe_value&#39;, &#39;change_in_swe_inch&#39;,
       &#39;snow_depth&#39;, &#39;air_temperature_observed_f&#39;],
      dtype=&#39;object&#39;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gridmet</span> <span class="o">=</span> <span class="n">dd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">gridmet_file</span><span class="p">,</span> <span class="n">blocksize</span><span class="o">=</span><span class="n">chunk_size</span><span class="p">)</span>
<span class="c1"># Drop the &#39;Unnamed: 0&#39; column</span>
<span class="n">gridmet</span> <span class="o">=</span> <span class="n">gridmet</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Unnamed: 0&quot;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;gridmet.columns = &quot;</span><span class="p">,</span> <span class="n">gridmet</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>gridmet.columns =  Index([&#39;day&#39;, &#39;lat&#39;, &#39;lon&#39;, &#39;air_temperature_tmmn&#39;,
       &#39;potential_evapotranspiration&#39;, &#39;mean_vapor_pressure_deficit&#39;,
       &#39;relative_humidity_rmax&#39;, &#39;relative_humidity_rmin&#39;,
       &#39;precipitation_amount&#39;, &#39;air_temperature_tmmx&#39;, &#39;wind_speed&#39;],
      dtype=&#39;object&#39;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">terrain</span> <span class="o">=</span> <span class="n">dd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">terrain_file</span><span class="p">,</span> <span class="n">blocksize</span><span class="o">=</span><span class="n">chunk_size</span><span class="p">)</span>
<span class="c1"># rename columns to match the other dataframes</span>
<span class="n">terrain</span> <span class="o">=</span> <span class="n">terrain</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span>
    <span class="s2">&quot;latitude&quot;</span><span class="p">:</span> <span class="s2">&quot;lat&quot;</span><span class="p">,</span> 
    <span class="s2">&quot;longitude&quot;</span><span class="p">:</span> <span class="s2">&quot;lon&quot;</span>
<span class="p">})</span>
<span class="c1"># select only the columns we need for the final output</span>
<span class="n">terrain</span> <span class="o">=</span> <span class="n">terrain</span><span class="p">[[</span><span class="s2">&quot;stationTriplet&quot;</span><span class="p">,</span> <span class="s2">&quot;elevation&quot;</span><span class="p">,</span> <span class="s2">&quot;lat&quot;</span><span class="p">,</span> <span class="s2">&quot;lon&quot;</span><span class="p">,</span> <span class="s1">&#39;Elevation&#39;</span><span class="p">,</span> <span class="s1">&#39;Slope&#39;</span><span class="p">,</span> <span class="s1">&#39;Aspect&#39;</span><span class="p">,</span> <span class="s1">&#39;Curvature&#39;</span><span class="p">,</span> <span class="s1">&#39;Northness&#39;</span><span class="p">,</span> <span class="s1">&#39;Eastness&#39;</span><span class="p">]]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;terrain.columns = &quot;</span><span class="p">,</span> <span class="n">terrain</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>terrain.columns =  Index([&#39;stationTriplet&#39;, &#39;elevation&#39;, &#39;lat&#39;, &#39;lon&#39;, &#39;Elevation&#39;, &#39;Slope&#39;,
       &#39;Aspect&#39;, &#39;Curvature&#39;, &#39;Northness&#39;, &#39;Eastness&#39;],
      dtype=&#39;object&#39;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">snowcover</span> <span class="o">=</span> <span class="n">dd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">fsca_file</span><span class="p">,</span> <span class="n">blocksize</span><span class="o">=</span><span class="n">chunk_size</span><span class="p">)</span>
<span class="c1"># rename columns to match the other dataframes</span>
<span class="n">snowcover</span> <span class="o">=</span> <span class="n">snowcover</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span>
    <span class="s2">&quot;latitude&quot;</span><span class="p">:</span> <span class="s2">&quot;lat&quot;</span><span class="p">,</span> 
    <span class="s2">&quot;longitude&quot;</span><span class="p">:</span> <span class="s2">&quot;lon&quot;</span>
<span class="p">})</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;snowcover.columns = &quot;</span><span class="p">,</span> <span class="n">snowcover</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>snowcover.columns =  Index([&#39;date&#39;, &#39;lat&#39;, &#39;lon&#39;, &#39;fSCA&#39;], dtype=&#39;object&#39;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Repartition DataFrames for optimized processing</span>
<span class="n">amsr</span> <span class="o">=</span> <span class="n">amsr</span><span class="o">.</span><span class="n">repartition</span><span class="p">(</span><span class="n">partition_size</span><span class="o">=</span><span class="n">chunk_size</span><span class="p">)</span>
<span class="n">snotel</span> <span class="o">=</span> <span class="n">snotel</span><span class="o">.</span><span class="n">repartition</span><span class="p">(</span><span class="n">partition_size</span><span class="o">=</span><span class="n">chunk_size</span><span class="p">)</span>
<span class="n">gridmet</span> <span class="o">=</span> <span class="n">gridmet</span><span class="o">.</span><span class="n">repartition</span><span class="p">(</span><span class="n">partition_size</span><span class="o">=</span><span class="n">chunk_size</span><span class="p">)</span>
<span class="n">gridmet</span> <span class="o">=</span> <span class="n">gridmet</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;day&#39;</span><span class="p">:</span> <span class="s1">&#39;date&#39;</span><span class="p">})</span>
<span class="n">terrain</span> <span class="o">=</span> <span class="n">terrain</span><span class="o">.</span><span class="n">repartition</span><span class="p">(</span><span class="n">partition_size</span><span class="o">=</span><span class="n">chunk_size</span><span class="p">)</span>
<span class="n">snow_cover</span> <span class="o">=</span> <span class="n">snowcover</span><span class="o">.</span><span class="n">repartition</span><span class="p">(</span><span class="n">partition_size</span><span class="o">=</span><span class="n">chunk_size</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;all the dataframes are partitioned&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>all the dataframes are partitioned
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Merge DataFrames based on specified columns</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;start to merge amsr and snotel&quot;</span><span class="p">)</span>
<span class="n">merged_df</span> <span class="o">=</span> <span class="n">dd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">amsr</span><span class="p">,</span> <span class="n">snotel</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;lat&#39;</span><span class="p">,</span> <span class="s1">&#39;lon&#39;</span><span class="p">,</span> <span class="s1">&#39;date&#39;</span><span class="p">],</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;outer&#39;</span><span class="p">)</span>
<span class="n">merged_df</span> <span class="o">=</span> <span class="n">merged_df</span><span class="o">.</span><span class="n">drop_duplicates</span><span class="p">(</span><span class="n">keep</span><span class="o">=</span><span class="s1">&#39;first&#39;</span><span class="p">)</span>
<span class="n">output_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">working_dir</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">final_output_name</span><span class="si">}</span><span class="s2">_snotel.csv&quot;</span><span class="p">)</span>
<span class="n">merged_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">output_file</span><span class="p">,</span> <span class="n">single_file</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;intermediate file saved to </span><span class="si">{</span><span class="n">output_file</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;start to merge gridmet&quot;</span><span class="p">)</span>
<span class="n">merged_df</span> <span class="o">=</span> <span class="n">dd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">merged_df</span><span class="p">,</span> <span class="n">gridmet</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;lat&#39;</span><span class="p">,</span> <span class="s1">&#39;lon&#39;</span><span class="p">,</span> <span class="s1">&#39;date&#39;</span><span class="p">],</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;outer&#39;</span><span class="p">)</span>
<span class="n">merged_df</span> <span class="o">=</span> <span class="n">merged_df</span><span class="o">.</span><span class="n">drop_duplicates</span><span class="p">(</span><span class="n">keep</span><span class="o">=</span><span class="s1">&#39;first&#39;</span><span class="p">)</span>
<span class="n">output_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">working_dir</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">final_output_name</span><span class="si">}</span><span class="s2">_gridmet.csv&quot;</span><span class="p">)</span>
<span class="n">merged_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">output_file</span><span class="p">,</span> <span class="n">single_file</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;intermediate file saved to </span><span class="si">{</span><span class="n">output_file</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;start to merge terrain&quot;</span><span class="p">)</span>
<span class="n">merged_df</span> <span class="o">=</span> <span class="n">dd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">merged_df</span><span class="p">,</span> <span class="n">terrain</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;lat&#39;</span><span class="p">,</span> <span class="s1">&#39;lon&#39;</span><span class="p">],</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;outer&#39;</span><span class="p">)</span>
<span class="n">merged_df</span> <span class="o">=</span> <span class="n">merged_df</span><span class="o">.</span><span class="n">drop_duplicates</span><span class="p">(</span><span class="n">keep</span><span class="o">=</span><span class="s1">&#39;first&#39;</span><span class="p">)</span>
<span class="n">output_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">working_dir</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">final_output_name</span><span class="si">}</span><span class="s2">_terrain.csv&quot;</span><span class="p">)</span>
<span class="n">merged_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">output_file</span><span class="p">,</span> <span class="n">single_file</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;intermediate file saved to </span><span class="si">{</span><span class="n">output_file</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;start to merge snowcover&quot;</span><span class="p">)</span>
<span class="n">merged_df</span> <span class="o">=</span> <span class="n">dd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">merged_df</span><span class="p">,</span> <span class="n">snow_cover</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;lat&#39;</span><span class="p">,</span> <span class="s1">&#39;lon&#39;</span><span class="p">,</span> <span class="s1">&#39;date&#39;</span><span class="p">],</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;outer&#39;</span><span class="p">)</span>
<span class="n">merged_df</span> <span class="o">=</span> <span class="n">merged_df</span><span class="o">.</span><span class="n">drop_duplicates</span><span class="p">(</span><span class="n">keep</span><span class="o">=</span><span class="s1">&#39;first&#39;</span><span class="p">)</span>
<span class="n">output_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">working_dir</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">final_output_name</span><span class="si">}</span><span class="s2">_snow_cover.csv&quot;</span><span class="p">)</span>
<span class="n">merged_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">output_file</span><span class="p">,</span> <span class="n">single_file</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;intermediate file saved to </span><span class="si">{</span><span class="n">output_file</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Save the merged DataFrame to a CSV file in chunks</span>
<span class="n">output_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">working_dir</span><span class="p">,</span> <span class="n">final_output_name</span><span class="p">)</span>
<span class="n">merged_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">output_file</span><span class="p">,</span> <span class="n">single_file</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Merge completed. </span><span class="si">{</span><span class="n">output_file</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>start to merge amsr and snotel
intermediate file saved to ../data/final_merged_data_3yrs_all_active_stations_v1.csv_snotel.csv
start to merge gridmet
intermediate file saved to ../data/final_merged_data_3yrs_all_active_stations_v1.csv_gridmet.csv
start to merge terrain
intermediate file saved to ../data/final_merged_data_3yrs_all_active_stations_v1.csv_terrain.csv
start to merge snowcover
intermediate file saved to ../data/final_merged_data_3yrs_all_active_stations_v1.csv_snow_cover.csv
Merge completed. ../data/final_merged_data_3yrs_all_active_stations_v1.csv
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Read the merged DataFrame, remove duplicate rows, and save the cleaned DataFrame to a new CSV file</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">dd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">work_dir</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="n">final_output_name</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;stationTriplet&#39;</span><span class="p">:</span> <span class="s1">&#39;object&#39;</span><span class="p">,</span>
       <span class="s1">&#39;station_name&#39;</span><span class="p">:</span> <span class="s1">&#39;object&#39;</span><span class="p">})</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop_duplicates</span><span class="p">(</span><span class="n">keep</span><span class="o">=</span><span class="s1">&#39;first&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">work_dir</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="n">final_output_name</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">single_file</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Data cleaning completed.&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Data cleaning completed.
</pre></div>
</div>
</div>
</div>
<ul>
<li><p><strong>Merge and Save AMSR and SNOTEL Data:</strong></p>
<ul class="simple">
<li><p>It merges AMSR and SNOTEL data on latitude, longitude, and date using an outer join. on=[‘lat’, ‘lon’, ‘date’] specifies the columns to merge on and how=’outer’ performs an outer join, retaining all rows from both Dataframes.</p></li>
<li><p>Removes duplicate rows.</p></li>
<li><p>Saves the merged DataFrame to a CSV file named {final_output_name}_snotel.csv.</p></li>
</ul>
</li>
<li><p><strong>Merge and Save Gridmet Data:</strong></p>
<ul class="simple">
<li><p>It merges the previously merged DataFrame with Gridmet data on latitude, longitude, and date using an outer join.</p></li>
<li><p>Removes duplicate rows.</p></li>
<li><p>Saves the updated merged DataFrame to a CSV file named {final_output_name}_gridmet.csv.</p></li>
</ul>
</li>
<li><p><strong>Merge and Save Terrain Data:</strong></p>
<ul class="simple">
<li><p>It merges the DataFrame again with terrain data on latitude and longitude using an outer join.</p></li>
<li><p>Removes duplicate rows.</p></li>
<li><p>Saves the updated merged DataFrame to a CSV file named {final_output_name}_terrain.csv</p></li>
</ul>
</li>
<li><p><strong>Merge and Save Snow Cover Data:</strong></p>
<ul class="simple">
<li><p>It merges the DataFrame once more with snow cover data on latitude, longitude, and date using an outer join.</p></li>
<li><p>Removes duplicate rows.</p></li>
<li><p>Saves the updated merged DataFrame to a CSV file named {final_output_name}_snow_cover.csv</p></li>
</ul>
</li>
<li><p><strong>Save Final Merged Data:</strong></p>
<ul class="simple">
<li><p>It saves the final merged DataFrame to a single CSV file named {final_output_name} in the specified working directory.</p></li>
</ul>
</li>
<li><p><strong>Data Cleaning:</strong></p>
<ul class="simple">
<li><p>It reads the final merged DataFrame again.</p></li>
<li><p>Removes duplicate rows.</p></li>
<li><p>Saves the cleaned DataFrame to a new CSV file with the same name {final_output_name}.</p></li>
</ul>
<p>single_file=True: Saves data to a single file.</p>
<p>index=False: Omits DataFrame index from the CSV.</p>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">sort_training_data</span><span class="p">(</span><span class="n">input_training_csv</span><span class="p">,</span> <span class="n">sorted_training_csv</span><span class="p">):</span>
    <span class="c1"># Read Dask DataFrame from CSV with increased blocksize and assuming missing data</span>
    <span class="n">ddf</span> <span class="o">=</span> <span class="n">dd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">input_training_csv</span><span class="p">,</span> <span class="n">assume_missing</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">blocksize</span><span class="o">=</span><span class="s1">&#39;10MB&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;stationTriplet&#39;</span><span class="p">:</span> <span class="s1">&#39;object&#39;</span><span class="p">,</span>
       <span class="s1">&#39;station_name&#39;</span><span class="p">:</span> <span class="s1">&#39;object&#39;</span><span class="p">})</span>

    <span class="c1"># Persist the Dask DataFrame in memory</span>
    <span class="n">ddf</span> <span class="o">=</span> <span class="n">ddf</span><span class="o">.</span><span class="n">persist</span><span class="p">()</span>

    <span class="c1"># Sort Dask DataFrame by three columns: date, lat, and Lon</span>
    <span class="n">sorted_ddf</span> <span class="o">=</span> <span class="n">ddf</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">,</span> <span class="s1">&#39;lat&#39;</span><span class="p">,</span> <span class="s1">&#39;lon&#39;</span><span class="p">])</span>

    <span class="c1"># Save the sorted Dask DataFrame to a new CSV file</span>
    <span class="n">sorted_ddf</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">sorted_training_csv</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">single_file</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;sorted training data is saved to </span><span class="si">{</span><span class="n">sorted_training_csv</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">final_final_output_file</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">work_dir</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="n">final_output_name</span><span class="si">}</span><span class="s1">&#39;</span>
<span class="n">sort_training_data</span><span class="p">(</span><span class="n">final_final_output_file</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">work_dir</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="n">final_output_name</span><span class="si">}</span><span class="s1">_sorted.csv&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>sorted training data is saved to ../data/final_merged_data_3yrs_all_active_stations_v1.csv_sorted.csv
</pre></div>
</div>
</div>
</div>
<p>Here we first read the CSV file into a Dask DataFrame, persists the Dask DataFrame in memory, which improves performance by keeping the data cached and readily accessible for further processing. Sorts the Dask DataFrame based on the specified columns (date, lat, lon). Saves the sorted Dask DataFrame to a new CSV file specified by sorted_training_csv. The index=False argument ensures that the index column is not included in the output CSV.</p>
</section>
<section id="conclusion-the-ready-to-train-dataset">
<h2>Conclusion: The Ready-to-Train Dataset<a class="headerlink" href="#conclusion-the-ready-to-train-dataset" title="Link to this heading">#</a></h2>
<p>The outcome of this journey is a rich, comprehensive dataset that stands ready for training SWE prediction models. Through meticulous merging, preprocessing, and cleaning, we’ve prepared a dataset that encapsulates the complexity of the environment and the specificity of snowpack conditions, laying a solid foundation for accurate and reliable SWE predictions.</p>
<p>This streamlined dataset not only facilitates more accurate models but also illustrates the importance of a thorough feature selection process in predictive modeling.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./chapters"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="amsr.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">AMSR</p>
      </div>
    </a>
    <a class="right-next"
       href="time_series.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Cumulative Time Series Analysis</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-to-the-data">Introduction to the Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-1-integrating-the-datasets-with-dask">Step 1: Integrating the Datasets with Dask</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#read-and-convert">Read and Convert</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#merge-on-common-ground">Merge on Common Ground</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#output">Output</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-2-preprocessing-for-feature-selection">Step 2: Preprocessing for Feature Selection</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-3-advanced-merging-and-cleaning">Step 3: Advanced Merging and Cleaning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion-the-ready-to-train-dataset">Conclusion: The Ready-to-Train Dataset</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Center for Spatial Information Science and Systems (CSISS), George Mason University
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>